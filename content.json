{"meta":{"title":"옐란 기술 블로그","subtitle":"<나를 위한 기록 노트>","description":"yelan's tech blog","author":"옐란","url":"https://jukyellow.github.io","root":"/"},"pages":[{"title":"","date":"2021-01-31T14:31:08.149Z","updated":"2021-01-31T14:31:08.149Z","comments":true,"path":"404.html","permalink":"https://jukyellow.github.io/404.html","excerpt":"","text":""},{"title":"About Me","date":"2021-01-31T01:43:33.000Z","updated":"2021-03-23T21:11:21.160Z","comments":true,"path":"about/index.html","permalink":"https://jukyellow.github.io/about/index.html","excerpt":"","text":"개발자의 꿈을 가져라!하는일(2021년 현재) 데이터 사이언티스트, 머신러닝 모델러 좌우명 뜻이 있는 곳에 길이 있다. 감명깊게 읽은 책 내가 단단해지는 새벽공부, 쳔년의내공 결국 해내는 사람들의 원칙 인생 짤 스위스 스카이 다이빙 히스토리 (2021.01) github 블로그 Open"},{"title":"Archives","date":"2021-01-31T11:49:56.000Z","updated":"2021-02-26T08:47:29.708Z","comments":false,"path":"archive/index.html","permalink":"https://jukyellow.github.io/archive/index.html","excerpt":"","text":""},{"title":"Tags","date":"2021-02-26T08:46:44.847Z","updated":"2021-02-26T08:46:44.847Z","comments":true,"path":"tags/index.html","permalink":"https://jukyellow.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2021-02-26T08:35:28.492Z","updated":"2021-02-26T08:35:28.492Z","comments":true,"path":"gtag.js","permalink":"https://jukyellow.github.io/gtag.js","excerpt":"","text":"window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-EG1ZFE1SGM');"},{"title":"","date":"2021-02-26T00:02:41.421Z","updated":"2021-02-26T00:00:07.857Z","comments":true,"path":"google54fa4245b3962d7d.html","permalink":"https://jukyellow.github.io/google54fa4245b3962d7d.html","excerpt":"","text":"google-site-verification: google54fa4245b3962d7d.html"}],"posts":[{"title":"육아서적1(감정코칭)","slug":"childcare","date":"2021-05-23T22:10:02.000Z","updated":"2021-05-25T21:53:47.838Z","comments":true,"path":"2021/05/24/childcare/","link":"","permalink":"https://jukyellow.github.io/2021/05/24/childcare/","excerpt":"","text":"참고도서: 존 가트맨/최성애 박사의 내 아이를 위한 감정코칭 [1] 감정을 잘 다루는 아이가 행복하다.아이, 감정 속에서 길을 잃다.(감정 이해의 중요성) 아이들은 부모로부터 이해받지 못한다고 느끼고 더 큰 문제 행동을 일으킵니다.자신의 기분을 좀 받아주고 이해해 달라고 울고 보채고 떼를 쓰거나 과격한 행동을 하는것인데도,부모들은 아이의 감정은 이해하지 못하고 행동에만 반응합니다. 감정을 무시당할수록 자존감이 낮고 스트레스에 약하다 아이가 울고 떼를 쓰고 짜증을 내고 소리를 지르는 등 어떤 형태로든 감정을 표현하는 것은 자기의 마음을 알아달라는 간절한 못짓입니다. 누군가로부터 감정을 이해받은 아이는 금방 감정을 추스르고 안정을 찾습니다. 그런데 대부분의 어른은 그런 마음을 몰라준 채 아이의 행동만 보고 야단을 칩니다. 감정을 알아주기는커녕 야단만 맞은 아이는 의기소침해집니다. 감정을 거부당하거나 무시당하는 일이 많을수록 아이는 자존감이 떨어집니다. 결국 자신과 남을 신뢰하거나 존중하지 못하기 때문에 함부로 행동하게 되며…’주의력결핍증 과잉행동장애아’레벨을 부여받기도 합니다. 감정은 다 받아주고, 행동은 한계를 정해준다 감정은 충분히 공감을 하지만 행동하는 데는 분명한 한계가 있다는 것을 깨닫게 해주어야합니다. 이것이 감정코칭의 핵심입니다. 아이의 감정을 추운히 읽어주고 공감해주었다면, 행동의 한계를 정해주었을때 아이가 순수히 받아들입니다. (땅에 떨어진 껌을 주어 먹었을때) “껌이 씹고 싶었구나, 우리 아이가 껌을 좋아하는거 잘 알아”, “그런데 엄마는 아이가 더러운 껌을 입에 넣고 병날까봐 걱정되 못먹게 한거란다, 누가 씹다가 땅에 버린 껌은 병균이 많아서 OO가 입에 넣으면 안되거든”… 카트맨 박사는 어릴때부터 아이에게 감정코칭을 해주는 것은 아이의 마음속에 스스로 원하는 바를 분명히 알고 찾을수 있도록 GPS를 심어주는 것과 같다고 표현합니다. [3] 아이의 마음을 여는 감정코칭 대화법칭찬하고 꾸짖을 때도 원칙이 중요하다.칭찬의 역효과 성격이나 인격에 대해 칭찬하지 않는다.: 자신의 성격이나 인격을 다른 사람으로부터 규정당하는 일은 어른에게도 부담스럽습니다. 하물며 어린아이는 말할 것도 없습니다. 따라서 “너는 천사 같구나”, “너처럼 정직한 아이가 그럴리가 없지” 등 아이의 인격이나 성격과 관련된 칭찬은 하지 않도록 합니다. 결과보다는 노력이나 행동에 대해 칭찬한다.: “그동안 열심히 공부하더니 성적이 많이 올랐구나. 네가 정말 자랑스러워” 적절한 타이밍에 칭찬한다.: 아이가 바람직한 행동을 했을때 즉각 반응해 주는것이 가장 좋습니다. 나중에 칭찬하더라도 하루를 넘기지 않는게 좋습니다. 기억은 대개 상황 속에서 감정과 함께 저장되는데, 당시의 상황과 감정에서 한참 벗어난 후의 칭찬은 상황적 기억으로 남기 어렵습니다. 칭찬의 이유를 구체적으로 설명한다. 제대로 꾸중하기 인격이나 성격에 대해 꾸짖지 않는다. 상황에 대해 꾸짖는다.: “책 돌려주겠다고 한 날짜가 지났구나(상황). 친구가 기다리겠다(상황) 엄마는 네가 친구와 약속을 지키지 못할 때 신용을 일을까봐 걱정이 된다(기분). 빌린 책은 약속한 날에 돌려주면 좋겠다(요청) 화난 감정 제대로 표현하기 아이가 명백히 잘못을 해서 화가 날 때는 감정을 표현해도 됩니다. 그런 감정 표현은 정당한 것입니다. 단, 감정을 표현할때 아이를 비난, 경멸, 조롱하면 안됩니다. 감정을 표현하되, 대화에는 감정을 싣지 않고 차분하게 이야기해야 효과적입니다. 먼저 사과하기 부모가 먼저 실수를 인정하면, 아이는 실수가 실패가 아니라는 것을 배웁니다. 부모가 잘못을 했을때 인정하는 것은 아이에게 좋은 역할 모델을 보여주는 것이 됩니다. 아이에게 있어 엄마, 아빠는 가장 위대한 사람입니다. 그런 어른이 실수를 인정하면, ‘아, 어른도 실수를 하는구나, 실수를 할때 저렇게 고칠수 있구나’ 생각하며, 실수를 했을때 어떻게 행동해야 하는지도 배웁니다.","categories":[{"name":"Childcare","slug":"childcare","permalink":"https://jukyellow.github.io/categories/childcare/"}],"tags":[{"name":"육아","slug":"육아","permalink":"https://jukyellow.github.io/tags/%EC%9C%A1%EC%95%84/"},{"name":"감정코치","slug":"감정코치","permalink":"https://jukyellow.github.io/tags/%EA%B0%90%EC%A0%95%EC%BD%94%EC%B9%98/"},{"name":"육아노트","slug":"육아노트","permalink":"https://jukyellow.github.io/tags/%EC%9C%A1%EC%95%84%EB%85%B8%ED%8A%B8/"}]},{"title":"시계열 분석(통계분석 기법)-Part2","slug":"statistics-time-series2","date":"2021-04-29T21:13:07.000Z","updated":"2021-05-14T22:20:08.150Z","comments":true,"path":"2021/04/30/statistics-time-series2/","link":"","permalink":"https://jukyellow.github.io/2021/04/30/statistics-time-series2/","excerpt":"","text":"개요: 통계학 기반 시계열 예측 모델의 이론과 실습을 통해 알아보자, 특히 ARIMA모델 사용법을 익혀보자 강좌: [K-MOOC강의] 시계열분석 기법과 응용, http://www.kmooc.kr/courses/course-v1:POSTECHk+IMEN677+2020_2/video ARIMA 모형을 이용한 비정상적 시계열 예측 Part1 진척률(2021.04.30): 1% 목차123Week5. ARCH/GARCH 모형Week6. 벡터자기회귀모형(VAR)Week7. 상태공간모형 Week5. ARCH/GARCH 모형ARCH 모형 시계혈 모형에서 오차항은 일정한 분산을 갖는 돍립적인 백색잡음으로 가정 금융관련 시계열에서 잔차는 백색잡음처럼 보이지만, 잔차의 절대값 또는 잔차 제곱항은 자기상관관계를 갖음 오차항 분산이 시간에 따라 일정하지 않고 변한다는 관측이 있음 오차항의 조건부 분산에 대한 모형을 고려 재무상품의 수익률 분산을 변동성(volatility)라하며 이의 분석이 중요 Engle(1982)이 ARCH(Autoregressive Conditional Heteroskedasticity)모형을 제시 ARCH 모형 시계열이 AR(1)모형을 따른다고 하자, 이때 오차항의 기대치와 분산이 존재 오차항이 서로 독립이 아니고 다음관계를 갖는다고 가정(즉 제곱오차항이 AR(q)모형을 따른다고 가정) 오차항의 조건부 분산, 이 형태 모형을 ARCH(q) 모형이라고 함 ARCH 모형의 정상성 조건 오차항의 조건없는 분산은 시간에 따라 일정(상수) 오차항의 조건부 분산과 조건없는 분산의 관계: ARCH모형이 정상일때 다음이 성립: ARCH(q) 모형의 정상적 조건: a1+a2…aq &lt; 1 평균 방정식과 분산방정식 ARCH모형은 오차항에 분산에 대한 것이므로 분산방정식이라 함 시계열 모형에서는 오차항이 포함된 평균방정식이 함께 사용되어야함 GARCH 모형GARCH 모형 Bollerslev(1986)이 ARCH모형을 확장한 것 조건부 분상항에 과거 시차의 조건부 분산항들이 추가된 것으로 다음의 형태를 가짐: Qt^2 = a0 + a1u^2t-1 … + Bqq^2… 오차항이 Garch(p,q)모형을 따른다 alpha들을 ARCH항, beta들을 GARCH항이라함: ARCH모형은 제곱오차항이 AR모형을 따르는 반면, GARCH모형은 제곱오차항이 ARMA모형을 따르게 된 GARCH 모형의 예측 평균방정식(수평적 모형), 분산방정식 GARCH(1,1) 시계열(반응치) 예측 시계열 예측오차 분산 조건부 분산(변동성) 예측 GARCH 모형의 변형 GARCH-M 모형(평균방정식에 조건부 분산을 포함) E-GARCH 모형: Nelson(1991) 제안 로그 변동성을 모형화 나쁜 뉴스가 좋은 뉴스보다 변동성에 더 큰 충격을 준다고 가정 T-GARCH모형(1993) 오차항이 양일때(좋은 소식) 조건부 분산에 미치는 영향보다 오차항이 음일때(나쁜소식) 미치는 여향이 크도록 고안(비대칭 모형) Week6.","categories":[{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/categories/data-scientist/"},{"name":"Note","slug":"data-scientist/note","permalink":"https://jukyellow.github.io/categories/data-scientist/note/"}],"tags":[{"name":"시계열분석","slug":"시계열분석","permalink":"https://jukyellow.github.io/tags/%EC%8B%9C%EA%B3%84%EC%97%B4%EB%B6%84%EC%84%9D/"},{"name":"time series","slug":"time-series","permalink":"https://jukyellow.github.io/tags/time-series/"},{"name":"ARCH","slug":"arch","permalink":"https://jukyellow.github.io/tags/arch/"},{"name":"GARCH","slug":"garch","permalink":"https://jukyellow.github.io/tags/garch/"},{"name":"VAR","slug":"var","permalink":"https://jukyellow.github.io/tags/var/"},{"name":"상태공간모형","slug":"상태공간모형","permalink":"https://jukyellow.github.io/tags/%EC%83%81%ED%83%9C%EA%B3%B5%EA%B0%84%EB%AA%A8%ED%98%95/"}]},{"title":"주식 기술지표 산출법 정리","slug":"stock-tech-indicator","date":"2021-04-24T23:24:40.000Z","updated":"2021-04-26T21:32:40.740Z","comments":true,"path":"2021/04/25/stock-tech-indicator/","link":"","permalink":"https://jukyellow.github.io/2021/04/25/stock-tech-indicator/","excerpt":"","text":"주식 투자관련 기술지표 정의/산출법(계산식)들을 정리해 본다. 참고도서: 퀀트 전략을 위한 인공지능 트레이닝 진척률(2021.04.25): 10% 목차1234567891.RA(이동평균션) : Standard deviation rolling average2.BOLL(볼린저 밴드) : Bollinger Band3.MACD : Moving Average Convergence/Divergence4.CCI : Commodity Channel Index # Momentum(모멘텀) Indicators5.ATR(변동성) : Average True Range6.MTM1 7.MTM38.ROC : Rate of change : ((price/prevPrice)-1)*1009.WPR : william percent range (Williams&#x27; %R) 이동평균선Pandas 구현 들쑥날쑥한 주가의 흐름을 몇일간의 평균적인 값으로 나타내는 지표를 이동평균선이라고 한다. 이동평균 구현 : rolling window를 정하고 평균을 계산12345price_df[&#x27;center&#x27;] = price_df[&#x27;Adj Close&#x27;].rolling(20).mean() # 이동평균선을 구한다.import matplotlib.pyplot as pltplt.plot(sample.index, sample[&#x27;Adj Close&#x27;], label=&quot;Adj Close&quot;)plt.plot(sample.index, sample[&#x27;center&#x27;], label=&quot;center&quot;) ta-lib로 적용 12345678910# colab 설치# (2020) https://stackoverflow.com/questions/49648391/how-to-install-ta-lib-in-google-colaburl = &#x27;https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files&#x27;!wget $url/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb!wget $url/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb!dpkg -i libta.deb ta.deb!pip install ta-libimport talibsample[&#x27;MA20&#x27;] = talib.SMA(sample[&#x27;Adj Close&#x27;],timeperiod=20) Sample jupyter notebook 이동평균계산 샘플","categories":[{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Finance","slug":"ai/finance","permalink":"https://jukyellow.github.io/categories/ai/finance/"}],"tags":[{"name":"Stock","slug":"stock","permalink":"https://jukyellow.github.io/tags/stock/"},{"name":"Indicatior","slug":"indicatior","permalink":"https://jukyellow.github.io/tags/indicatior/"},{"name":"볼린저밴드","slug":"볼린저밴드","permalink":"https://jukyellow.github.io/tags/%EB%B3%BC%EB%A6%B0%EC%A0%80%EB%B0%B4%EB%93%9C/"},{"name":"이동평균선","slug":"이동평균선","permalink":"https://jukyellow.github.io/tags/%EC%9D%B4%EB%8F%99%ED%8F%89%EA%B7%A0%EC%84%A0/"},{"name":"모멘텀","slug":"모멘텀","permalink":"https://jukyellow.github.io/tags/%EB%AA%A8%EB%A9%98%ED%85%80/"},{"name":"변동성","slug":"변동성","permalink":"https://jukyellow.github.io/tags/%EB%B3%80%EB%8F%99%EC%84%B1/"}]},{"title":"비트코인 트레이드 경진대회","slug":"bit-trade-competition1","date":"2021-04-23T23:00:21.000Z","updated":"2021-04-23T23:32:18.364Z","comments":true,"path":"2021/04/24/bit-trade-competition1/","link":"","permalink":"https://jukyellow.github.io/2021/04/24/bit-trade-competition1/","excerpt":"","text":"통계기반 시계열 처리 모델(ARIMA)을 실제 주식(비트코인) 데이터에 접목하여 어떤 결과가 나오는지 확인해보자 기본 baseline 코드를 수정하여 작업하였고, 비트 트레이드 1차 결과 상위 7% 결과에 진입함(work-day 3일 정도 작업한듯) 튜닝 요소가 많이 남았지만 1차로 관련 작업내용을 기록해 둔다. 2차 대회 안내: https://dacon.io/competitions/official/235712/overview/description/ 전체코드: https://github.com/jukyellow/ai-competiton/blob/master/01_bit_trade/competition(dacon)_bitcoin_01_Arima_By_Coin_20210322_02.ipynb 목차1234567891. 접근전략2. 개발환경, lib설치3. 데이터 로딩/확인4. ARIMA 모델과 페라미터5. 학습데이터 분석(생략)6. ARIMA 모델 적용7. 트레이딩 모듈/로직8. 모의투자 결과확인9. submission 제출 접근전략 비정상적 시계열 데이터를 예측하는 전통적 기법은 통계기반의 ARIMA모델을 주로 사용함 LSTM모델로도 추가로 확인필요(예정), 6시간학습 및 1시간후 data 예측순으로 data 구성하면 됨! baseline의 코드는, 전체 코인(9개)에 대해서 하나로 묶어서 학습 및 예측함: 코인별로 나눠서 예측하는게 상식적이므로, 코인별로 나눠서 작업 매매 관련해서는 최적화가 필요한데, 관련 기법에 대한 식견이 없어서 baseline코드를 차용함(임으로 조정해보니 결과가 나빠지기만 했음): 최적매매를 위해 강화학습이 필요할 듯 개발환경 구성 google colab jupyter notebook 환경에서 개발 talib는 이동평균션 등을 구할때 필요함, ARIMA만 사용하는 경우 생략가능1234567# (2020) https://stackoverflow.com/questions/49648391/how-to-install-ta-lib-in-google-colaburl = &#x27;https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files&#x27;!wget $url/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb!wget $url/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb!dpkg -i libta.deb ta.deb!pip install ta-libimport talib 데이터 로딩/확인 data size는 대략 500M정도 이며, 다운로드는 해당 사이트에서 가능: (2차 data) https://dacon.io/competitions/official/235712/data/ 데이터 다운로드 나는 google drive에 올려두고 다운받는 식으로 진행12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 1.data 다운로드#구글 드라이브에서 다운로드from google.colab import authauth.authenticate_user()from googleapiclient.discovery import builddrive_service = build(&#x27;drive&#x27;, &#x27;v3&#x27;)import iofrom io import BytesIO from googleapiclient.http import MediaIoBaseDownloadTEMP_PATH = &#x27;/tmp/&#x27;def gcp_download(file_name, key): #3. 모델 다운로드 #https://drive.google.com/open?id=1TlvbayGRCjAI6bOZrUYMmv6g6b95rnRM request = drive_service.files().get_media(fileId=key) downloaded = io.BytesIO() downloader = MediaIoBaseDownload(downloaded, request) done = False while done is False: status, done = downloader.next_chunk() if status: print(&quot;Download %%%d%%.&quot; % int(status.progress() * 100)) print(&quot;Download Complete!&quot;) downloaded.seek(0) with open(TEMP_PATH + file_name, &#x27;wb&#x27;) as f: f.write(downloaded.read())#https://drive.google.com/file/d/1ckwh5Tp9PRSPu5dhfG8IzK8VjADQRplAdown_file_name = &#x27;train_x_df.csv&#x27;gcp_download(down_file_name, &#x27;1ckwh5Tp9PRSPu5dhfG8IzK8VjADQRplA&#x27;) # https://drive.google.com/file/d/1PgnSkO8h2Bsn6B8PdsJi9D_TvD0NvbmU/view?usp=sharingdown_file_name = &#x27;train_y_df.csv&#x27;gcp_download(down_file_name, &#x27;1PgnSkO8h2Bsn6B8PdsJi9D_TvD0NvbmU&#x27;) # https://drive.google.com/file/d/1SZ84Xtr-okI830fOAcKmA-5X09iqETVwdown_file_name = &#x27;test_x_df.csv&#x27;gcp_download(down_file_name, &#x27;1SZ84Xtr-okI830fOAcKmA-5X09iqETVw&#x27;) # https://drive.google.com/file/d/1SZ84Xtr-okI830fOAcKmA-5X09iqETVwdown_file_name = &#x27;sample_submission.csv&#x27;gcp_download(down_file_name, &#x27;1SZ84Xtr-okI830fOAcKmA-5X09iqETVw&#x27;) !mv /tmp/sample_submission.csv /content/!mv /tmp/test_x_df.csv /content/!mv /tmp/train_y_df.csv /content/!mv /tmp/train_x_df.csv /content/ data 로딩 12345678910111213141516171819202122232425262728293031# 2. data 불러오기import pandas as pddata_path = &#x27;/content&#x27;train_x_df = pd.read_csv(data_path + &quot;/train_x_df.csv&quot;)train_y_df = pd.read_csv(data_path + &quot;/train_y_df.csv&quot;)test_x_df = pd.read_csv(data_path + &quot;/test_x_df.csv&quot;)print(len(train_x_df))print(train_x_df.head())print()print(train_x_df.iloc[:, 2:].head())10159560 sample_id time coin_index ... trades tb_base_av tb_quote_av0 0 0 7 ... 451.157288 7.326834e+05 37725.1835941 0 1 7 ... 39.231071 0.000000e+00 0.0000002 0 2 7 ... 58.846603 1.664967e+04 857.3778083 0 3 7 ... 431.541779 2.189147e+06 112811.0468754 0 4 7 ... 176.539810 0.000000e+00 0.000000[5 rows x 12 columns] coin_index open high ... trades tb_base_av tb_quote_av0 7 1.010004 1.010004 ... 451.157288 7.326834e+05 37725.1835941 7 1.009808 1.009808 ... 39.231071 0.000000e+00 0.0000002 7 1.009808 1.010200 ... 58.846603 1.664967e+04 857.3778083 7 1.010200 1.011181 ... 431.541779 2.189147e+06 112811.0468754 7 1.010985 1.010985 ... 176.539810 0.000000e+00 0.000000[5 rows x 10 columns] 코인별로 data 갯수 확인123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# coin별로 전체 샘플 건수 확인train_x_df_group = train_x_df.groupby(&quot;coin_index&quot;).size()print(train_x_df_group.head(12))print()# coin별로 샘플 사이즈 확인(23시간으로 나눈값)train_x_df_group = train_x_df.groupby(&quot;coin_index&quot;).size()/1380 # 23시간 동안의 data임으로 coin단위로 sample건수 환산print(train_x_df_group.head(12))print()train_y_df_group = train_y_df.groupby(&quot;coin_index&quot;).size()/1380 # 23시간 동안의 data임으로 coin단위로 sample건수 환산print(train_y_df_group.head(12))print()test_x_df_group = test_x_df.groupby(&quot;coin_index&quot;).size()/1380 # 23시간 동안의 data임으로 coin단위로 sample건수 환산print(test_x_df_group.head(12))### 코인별로 다르게 예측하고, sum해야함!coin_index0 12516601 5271602 1393803 1780204 12834005 7521006 14697007 13068608 16256409 1625640dtype: int64coin_index0 907.01 382.02 101.03 129.04 930.05 545.06 1065.07 947.08 1178.09 1178.0dtype: float64coin_index0 78.8695651 33.2173912 8.7826093 11.2173914 80.8695655 47.3913046 92.6086967 82.3478268 102.4347839 102.434783dtype: float64coin_index0 53.01 53.02 53.03 53.04 53.05 53.06 53.07 53.08 53.09 52.0dtype: float64 코인별 DataSet 나누기 1234567891011121314# 코인별 data-set 분리train_x_df_map = &#123;&#125;train_y_df_map = &#123;&#125;test_x_df_map = &#123;&#125;for idx in range(10): print(&quot;idx:&quot;, idx) df_x = train_x_df.loc[train_x_df.loc[:, &quot;coin_index&quot;]==idx] df_y = train_y_df.loc[train_y_df.loc[:, &quot;coin_index&quot;]==idx] df_z = test_x_df.loc[test_x_df.loc[:, &quot;coin_index&quot;]==idx] train_x_df_map[idx] = df_x.round(3) train_y_df_map[idx] = df_y.round(3) test_x_df_map[idx] = df_z.round(3) 코인별로 3차원 데이터 만들기: 엑셀로 2차원 형태의 데이터가 존재하고, 3차원(10가지 Feature, N개의 샘플, 23시간동안의 분단위 데이터)으로 구성됨123456789101112131415161718192021222324252627282930313233def df2d_to_array3d(df_2d): # 입력 받은 2차원 데이터 프레임을 3차원 numpy array로 변경하는 함수 feature_size = df_2d.iloc[:,2:].shape[1] time_size = len(df_2d.time.value_counts()) sample_size = len(df_2d.sample_id.value_counts()) array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size]) return array_3dtrain_x_df_map_arr = &#123;&#125;train_y_df_map_arr = &#123;&#125;test_x_df_map_arr = &#123;&#125;# 코인별로 나눠서 3차원 data 만들기for idx in train_x_df_map.keys(): train_x_df_map_arr[idx] = df2d_to_array3d(train_x_df_map[idx])for idx in train_y_df_map.keys(): train_y_df_map_arr[idx] = df2d_to_array3d(train_y_df_map[idx])for idx in test_x_df_map.keys(): test_x_df_map_arr[idx] = df2d_to_array3d(test_x_df_map[idx])# train_x_array = df2d_to_array3d(train_sample_df)# train_y_array = df2d_to_array3d(val_sample_df)# test_x_array = df2d_to_array3d(test_x_df)print(f&#x27;&#x27;&#x27;train_x_array &#123;train_x_df_map_arr[0].shape&#125;train_y_array &#123;train_y_df_map_arr[0].shape&#125;test_x_array &#123;test_x_df_map_arr[0].shape&#125;&#x27;&#x27;&#x27;)train_x_array (907, 1380, 46)train_y_array (907, 120, 46)test_x_array (53, 1380, 46) data 가시화 확인 12345678910111213def plot_series(x_series, y_series): #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다. plt.plot(x_series, label = &#x27;input_series&#x27;) plt.plot(np.arange(len(x_series), len(x_series)+len(y_series)), y_series, label = &#x27;output_series&#x27;) plt.axhline(1, c = &#x27;red&#x27;) plt.legend()# sample_id 1012에 해당하는 sample의 분단위 시가 변동 정보 시각화idx = 100#plot_series(train_x_array[idx,:,1], train_y_array[idx,:,1])plot_series(train_x_df_map_arr[0][idx,:, 1], train_y_df_map_arr[0][idx,:, 1])plt.show() ARIMA 모델과 페라미터 lib import1234567891011121314import numpy as npimport pandas as pdimport gcimport mathimport os.pathimport timeimport matplotlib.pyplot as pltfrom datetime import timedelta, datetimefrom dateutil import parserfrom tqdm import tqdmimport copyfrom statsmodels.tsa.arima_model import ARIMA # arima_model!import warningswarnings.filterwarnings(&quot;ignore&quot;) ARIMA 페라미터(p,d,q)의 최적화가 필요함: (참고-이론) https://jukyellow.github.io/2021/04/12/statistics-time-series/: p는 AR모형의 페라미터, q는 MA모형의 페라미터: d는 비정상적 시계열 data를 차분하여 정상 시계열로 변환할때, 1차~N차 차분하는 값, 차분-인근한 두 값의 차이를 산출123456# 시계열 표현방식- 자기회귀(AR: autoregressive) 표현방식: 시점 t의 값(Zt)을 과거 시점의 값들을 이용한 회귀식으로 표현- 자기회귀 과정이동평균(MA: Moving average) 표현방식: 시점t의 값(Zt)를 현재와 과거시점의 백색잡음으로 표현, 이동평균 과정이라고도 함 ACF, PACF의 그래프를 보고 간소하게 판단하고 진행: (현시점:21/04/24) 학습이 더 필요한 상태로 참고 블로로 갈음: (참고) https://byeongkijeong.github.io/ARIMA-with-Python/123456789101112131415161718192021# Arima (p,q,d) 최적화import matplotlib.pyplot as pltfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacfidx = 100#x_series = train_x_df_map_arr[0][idx,:,1] # 1: Open 가격#x_series = train_x_df_map[0].loc[:, &#x27;open&#x27;] # 천만row;;x_series = train_x_df_map[0].loc[0:100000, &#x27;open&#x27;]print(x_series)print()plot_acf(x_series)plot_pacf(x_series)plt.show()## 적절한 차분 차수의 계산을 위해 우선 1차 차분을 하고, ACF 및 PACF를 다시 계산한다.diff_1= x_series.diff(periods=1).iloc[1:]diff_1.plot()plot_acf(diff_1)plot_pacf(diff_1)plt.show() ARIMA 모델 적용Train 훈련 Train x와 y는 모델의 결과를 확인하고(train/validation), 페라미터를 최적화하는 용으로 사용되는 듯하다? submission 제출은 Test셋으로 학습한 모델의 결과로 돌려서 제출하였다. 사실, Train셋으로 학습하고, Validation(y)셋으로 검증하고, Test셋으로 최종 결과를 확인해야하는데, Test셋으로 학습하는게 맞는건가 의문점이 있긴하다. 나는 ARIMA모델을 사용할 경우 페라미터 최적화가 필요하니, Train X/Y를 그 용도로 사용하고, 최종 Test셋으로 학습하고 submission data를 돌려서 제출하였다. 1234567891011121314151617181920212223# train 샘플 훈련하기idx = 100# train data 중 sample_id 1121에 해당하는 x_series로 arima 모델을 학습한 후# y_sereis를 추론x_series = train_x_df_map_arr[0][idx,:,1]y_series = train_x_df_map_arr[0][idx,:,1]# ARIMA의 (p,d,q) 값은 최적화 되지않은 값 입니다.model = ARIMA(x_series, order=(3,0,1)) #model = ARIMA(x_series, order=(5,1,1)) fit = model.fit()#fit = model.fit(trend=&#x27;nc&#x27;,full_output=True, disp=1)print(type(fit))#preds = fit.predict(1,120, typ=&#x27;levels&#x27;)preds = fit.predict(1,120)plot_series(x_series, y_series)plt.plot(np.arange(1380, 1380+120), preds, label = &#x27;prediction&#x27;)plt.legend()plt.show()print(fit.summary()) 학습 및 추론하기 12345678910111213141516171819202122232425# ARIMA의 (p,d,q) 값이 (5,1,1)에서 수렴하지 않을 경우# (4,1,1)로 변경하여 다시 학습 및 추론for idx in tqdm(range(valid_x_array.shape[0])): try: try: x_series = valid_x_array[idx,:,1] #model = ARIMA(x_series, order=(5,1,1)) model = ARIMA(x_series, order=(3,0,1)) fit = model.fit() preds = fit.predict(1,120, typ=&#x27;levels&#x27;) valid_pred_array[idx,:] = preds# - (preds[0]-x_series[-1]) except: print(&quot;order 4 1 1&quot;) x_series = valid_x_array[idx,:,1] model = ARIMA(x_series, order=(4,1,1)) fit = model.fit() preds = fit.predict(1,120, typ=&#x27;levels&#x27;) valid_pred_array[idx,:] = preds except: print(idx, &quot; 샘플은 수렴하지 않습니다.&quot;) # ARIMA의 (p,d,q) 값이 (5,1,1), (4,1,1)에서 수렴하지 않을 경우 # 모두 0으로 채움 pass 트레이딩 모듈/로직추론한 data로 매매시점 잡기 baseline코드 그대로 사용, 115% 상승인 경우만 전략 매수 매수후 최고치로 예상한 시점에 매도123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# valid_pred_array 로부터 buy_quantity, sell_time 구하기#def array_to_submission(x_array, pred_array):def array_to_submission(valid_x_df_0, pred_array): # 입력 x_arrry와 출력 pred_arry를 통해서 # buy_quantitiy와 sell_time을 결정 submission = pd.DataFrame(np.zeros([pred_array.shape[0],2], np.int64), columns = [&#x27;buy_quantity&#x27;, &#x27;sell_time&#x27;]) #print(&#x27;submission1:&#x27;, submission.head()) submission = submission.reset_index() #print(&#x27;submission2:&#x27;, submission.head()) submission.loc[:, &#x27;buy_quantity&#x27;] = 0.1 buy_price = [] for idx, sell_time in enumerate(np.argmax(pred_array, axis = 1)): buy_price.append(pred_array[idx, sell_time]) buy_price = np.array(buy_price) # 115% 이상 상승한하고 예측한 sample에 대해서만 100% 매수 submission.loc[:, &#x27;buy_quantity&#x27;] = (buy_price &gt; 1.15) * 1 # 모델이 예측값 중 최대 값에 해당하는 시간에 매도 submission[&#x27;sell_time&#x27;] = np.argmax(pred_array, axis = 1) submission.columns = [&#x27;sample_id&#x27;,&#x27;buy_quantity&#x27;, &#x27;sell_time&#x27;] submission[&#x27;sample_id_orgin&#x27;] = valid_x_df_0.sample_id.unique() return submissionvalid_submission = array_to_submission(valid_x_df_0, valid_pred_array)print(valid_submission)submission1: buy_quantity sell_time0 0 01 0 02 0 03 0 04 0 0submission2: index buy_quantity sell_time0 0 0 01 1 0 02 2 0 03 3 0 04 4 0 0 sample_id buy_quantity sell_time sample_id_orgin0 0 0 24 11 1 0 119 162 2 0 13 193 3 0 21 264 4 0 118 30.. ... ... ... ...120 120 0 83 973121 121 0 12 978122 122 0 53 984123 123 0 55 989124 124 0 51 998[125 rows x 4 columns] 모의투자 결과확인투자후 금액 계산 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# 투자 후 금액 계산하기def df2d_to_answer(df_2d): # valid_y_df로부터 # open 가격 정보가 포함된 # [샘플 수, 120분] 크기의 # 2차원 array를 반환하는 함수 feature_size = df_2d.iloc[:,2:].shape[1] #print(&#x27;feature_size:&#x27;, feature_size) time_size = len(df_2d.time.value_counts()) #print(&#x27;time_size:&#x27;, time_size) sample_size = len(df_2d.sample_id.value_counts()) #print(&#x27;sample_size:&#x27;, sample_size) sample_index = df_2d.sample_id.value_counts().index #print(&#x27;df_2d.sample_id.value_counts():&#x27;, df_2d.sample_id.value_counts()) #print(&#x27;sample_index:&#x27;, sample_index) array_2d = df_2d.open.values.reshape([sample_size, time_size]) #print(&#x27;array_2d.shape:&#x27;, array_2d.shape) sample_index = list(sample_index) return array_2d, sample_indexdef COIN(y_df, submission, df2d_to_answer = df2d_to_answer, money = 10000): # 2차원 데이터프레임에서 open 시점 데이터만 추출하여 array로 복원 # sample_id정보를 index에 저장 y_array, index = df2d_to_answer(y_df) # index: sample_id index #print(&#x27;y_array.shape:&#x27;, y_array.shape) #print(&#x27;index:&#x27;, index) # index 기준으로 submission을 다시 선택 #print(&#x27;submission.columns[0]:&#x27;, submission.columns[0]) #submission = submission.set_index(submission.columns[0]) # sample_id #index를 다시 잡으면 아래 for 순회시 sample_id로 잡혀서 out_of_range발생.. 그냥 row_index를 사용하도록 둠. #submission = submission.set_index(&#x27;sample_id_orgin&#x27;) # sample_id #print(&#x27;submission.shape:&#x27;, submission.shape) #submission = submission.iloc[index, :] #print(&#x27;submission:&#x27;, submission.head()) #print(&#x27;submission:&#x27;, submission.tail()) # 초기 투자 비용은 10000 달러 total_momey = money # dolors total_momey_list = [] # 가장 처음 sample_id값 start_index = submission.index[0] #print(&#x27;submission.index:&#x27;, submission.index) #print(&#x27;len(y_array):&#x27;, len(y_array)) for row_idx in submission.index: sell_time = submission.loc[row_idx, &#x27;sell_time&#x27;] #print(&#x27;row_idx - start_index:&#x27;, row_idx - start_index) buy_price = y_array[row_idx - start_index, 0] sell_price = y_array[row_idx - start_index, sell_time] buy_quantity = submission.loc[row_idx, &#x27;buy_quantity&#x27;] * total_momey residual = total_momey - buy_quantity ratio = sell_price / buy_price total_momey = buy_quantity * ratio * 0.9995 * 0.9995 + residual total_momey_list.append(total_momey) return total_momey, total_momey_listtotal_momey, total_momey_list = COIN(valid_y_df_0, valid_submission)# 투자 후 금액print(total_momey)# 투자 히스토리plt.plot(total_momey_list)plt.title(&quot;history&quot;)plt.show() submission 제출TestSet으로 학습 123456789101112131415161718192021222324252627282930test_x_array_map = &#123;&#125;for idx in range(10): test_x_array_map[idx] = test_x_df_map_arr[idx]print(test_x_array_map[0].shape)# test 데이터 학습하고 추론하기 ??# 훈련모델로 test 데이터 추론만 하면되는거 아닌가??test_pred_array_map = &#123;&#125;for key in test_x_array_map.keys(): test_x_array = test_x_array_map[key] test_pred_array_map[key] = np.zeros([test_x_array.shape[0],120]) for idx in tqdm(range(test_x_array.shape[0])): try: try: x_series = test_x_array[idx,:,1] model = ARIMA(x_series, order=(5,1,1)) fit = model.fit() preds = fit.predict(1,120, typ=&#x27;levels&#x27;) test_pred_array_map[key][idx,:] = preds except: x_series = test_x_array[idx,:,1] model = ARIMA(x_series, order=(4,1,1)) fit = model.fit() preds = fit.predict(1,120, typ=&#x27;levels&#x27;) test_pred_array_map[key][idx,:] = preds except: print(idx, &quot; 샘플은 수렴하지 않습니다.&quot;) pass 가시화 확인 : ARIMA모델은 summary정보로 페라미터의 최적화 여부를 판단할수 있다고 함(아직 학습 부족)12345678910111213141516171819202122def plot_series2(x_series): #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다. plt.plot(x_series, label = &#x27;input_series&#x27;) # plt.plot(np.arange(len(x_series), len(x_series)+len(y_series)), # y_series, label = &#x27;output_series&#x27;) plt.axhline(1, c = &#x27;red&#x27;) plt.legend()x_series = test_x_array_map[0]print(x_series.shape)print(x_series[idx, :, 1].shape)preds = test_pred_array_map[0]print(preds.shape)print(preds[idx, :].shape)idx = 0plot_series2(x_series[idx, :, 1])plt.plot(np.arange(1380, 1380+120), preds[idx, :], label = &#x27;prediction&#x27;)plt.legend()plt.show()print(fit.summary()) 모델 추론 1234567891011121314151617181920212223submission_map = &#123;&#125;for idx in test_x_df_map.keys(): test_x_df = test_x_df_map[idx] #print(test_x_df.shape) # 추론한 test_pred_array를 바탕으로 submission df 생성하기 submission_map[idx] = array_to_submission(test_x_df, test_pred_array_map[idx]) for idx in submission_map.keys(): if idx == 0: submission = submission_map[0] continue submission = pd.concat([submission, submission_map[idx]], ignore_index=True)#submission.to_csv(&quot;submission.csv&quot;, index = False)submission.head() sample_id buy_quantity sell_time sample_id_orgin0 0 0 17 11 1 0 74 132 2 0 0 163 3 0 15 294 4 0 112 31 제출본 파일 정리 및 파일 생성123456789101112131415161718192021print(len(submission))print(submission.head())# 컬럼제거submission = submission.drop(&quot;sample_id&quot;, axis=1) # df = df.drop(columns=&quot;A&quot;)print(submission.head())# 컬럼(index) 이름 변경submission.rename(columns = &#123;&#x27;sample_id_orgin&#x27; : &#x27;sample_id&#x27;&#125;, inplace = True)#submission.columns = [&#x27;sample_id&#x27;, &#x27;buy_quantity&#x27;, &#x27;sell_time&#x27;]print(submission.head())#index 변경submission = submission.set_index(&quot;sample_id&quot;)print(submission.head())# 정렬submission = submission.sort_values(by=[&quot;sample_id&quot;], ascending=True)print(submission.head(10))submission.to_csv(&quot;submission.csv&quot;, index = True) 결과분석: 24개의 data에 대해서 115% 상승할걸로 예측하고 매수/매매 수행함.123456print(submission.buy_quantity.value_counts())print(submission.shape)0 5051 24Name: buy_quantity, dtype: int64(529, 2) 모의투자 결과 확인12345678910111213141516171819202122232425262728sum_total_momey = 0for idx in test_x_df_map.keys(): test_x_df = test_x_df_map[idx] submission = submission_map[idx] total_momey, total_momey_list = COIN(test_x_df, submission, money=1000) sum_total_momey += total_momey # 투자 후 금액 print(total_momey)print(&#x27;sum_total_momey:&#x27;, sum_total_momey)# 투자 히스토리plt.plot(total_momey_list)plt.title(&quot;history&quot;)plt.show()1009.74216821076491006.31810529132831011.69214916828411031.43964177055391033.5609178283941513.90694705451411006.89500061469041043.16749913828771013.57081484577841004.5865519310078sum_total_momey: 10674.879795853603 sumission 파일 제출 생성된 submission.csv파일을 제출! 최종결과","categories":[{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Competition","slug":"ai/competition","permalink":"https://jukyellow.github.io/categories/ai/competition/"}],"tags":[{"name":"ARMA","slug":"arma","permalink":"https://jukyellow.github.io/tags/arma/"},{"name":"ARIMA","slug":"arima","permalink":"https://jukyellow.github.io/tags/arima/"},{"name":"비트코인","slug":"비트코인","permalink":"https://jukyellow.github.io/tags/%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8/"},{"name":"모의투자","slug":"모의투자","permalink":"https://jukyellow.github.io/tags/%EB%AA%A8%EC%9D%98%ED%88%AC%EC%9E%90/"},{"name":"시계열","slug":"시계열","permalink":"https://jukyellow.github.io/tags/%EC%8B%9C%EA%B3%84%EC%97%B4/"},{"name":"ACF","slug":"acf","permalink":"https://jukyellow.github.io/tags/acf/"},{"name":"PACF","slug":"pacf","permalink":"https://jukyellow.github.io/tags/pacf/"}]},{"title":"헬스장 회원 행동(이용빈도) 예측","slug":"py100-ch04-user-action-pred","date":"2021-04-23T00:21:21.000Z","updated":"2021-04-23T01:25:51.606Z","comments":true,"path":"2021/04/23/py100-ch04-user-action-pred/","link":"","permalink":"https://jukyellow.github.io/2021/04/23/py100-ch04-user-action-pred/","excerpt":"","text":"파이썬을 기반으로 데이터 분석 기술을 습득해 보자! 참고도서: 파이썬 데이터 분석 실무 테크닉 100 data: https://github.com/jukyellow/pyda100/tree/master/4%EC%9E%A5 전체소스: https://github.com/jukyellow/data-scientist/blob/main/01_Base_Skills/(book)Practical-Techniques_100/04_User_Action_Predict_20210423.ipynb 목차123451. 데이터 로딩/확인2. 회원 특징별 클러스터링3. 헬스장 사용빈도 예측3-1. 6개월간 DataSet 준비3-2. Regression 예측 데이터 로딩/확인데이터 로딩 pandas로 csv파일 read하여 DataFrame으로 반환123456import pandas as pduselog = pd.read_csv(&#x27;use_log.csv&#x27;)print(uselog.isnull().sum())customer = pd.read_csv(&#x27;customer_join.csv&#x27;)print(customer.isnull().sum()) 데이터 확인 uselog는 사용자의 이용빈도를 체크하기 위한 목적으로 활용 customer는 회원정보 및 월 사용기간/빈도(min,max 등 추가)관련 정보 존재123456789101112131415uselog.head()log_id customer_id usedate0 L00000049012330 AS009373 2018-04-011 L00000049012331 AS015315 2018-04-012 L00000049012332 AS040841 2018-04-013 L00000049012333 AS046594 2018-04-014 L00000049012334 AS073285 2018-04-01customer.head() customer_id name class gender start_date end_date campaign_id is_deleted class_name price campaign_name mean median max min routine_flg calc_date membership_period0 OA832399 XXXX C01 F 2015-05-01 NaN CA1 0 0_종일 10500 2_일반 4.833333 5.0 8 2 1 2019-04-30 471 PL270116 XXXXX C01 M 2015-05-01 NaN CA1 0 0_종일 10500 2_일반 5.083333 5.0 7 3 1 2019-04-30 472 OA974876 XXXXX C01 M 2015-05-01 NaN CA1 0 0_종일 10500 2_일반 4.583333 5.0 6 3 1 2019-04-30 473 HD024127 XXXXX C01 F 2015-05-01 NaN CA1 0 0_종일 10500 2_일반 4.833333 4.5 7 2 1 2019-04-30 474 HD661448 XXXXX C03 F 2015-05-01 NaN CA1 0 2_야간 6000 2_일반 3.916667 4.0 6 1 1 2019-04-30 47 회원 특징별 클러스터링클러스터링 Feature 추출 회원별 사용기간, 사용빈도에 관한 특징 추출 최종 월별 사용빈도 예측시, 영향을 끼칠걸로 판단되는 특징을 임으로 선택하여 추출(다른 feature 추가 사용가능)12345678customer_clustering = customer[[&quot;mean&quot;, &quot;median&quot;,&quot;max&quot;, &quot;min&quot;, &quot;membership_period&quot;]]customer_clustering.head()mean median max min membership_period0 4.833333 5.0 8 2 471 5.083333 5.0 7 3 472 4.583333 5.0 6 3 473 4.833333 4.5 7 2 474 3.916667 4.0 6 1 47 K-means 군집화1234567891011121314151617181920# 클러스터링으로 회원을 그룹화하자from sklearn.cluster import KMeansfrom sklearn.preprocessing import StandardScalersc = StandardScaler()# 스케일을 맞추지 않으면 특정 이상치에 대해 크게 반응하여 잘못된 결과가 발생할수 있음customer_clustering_sc = sc.fit_transform(customer_clustering)kmeans = KMeans(n_clusters=4, random_state=0)clusters = kmeans.fit(customer_clustering_sc)customer_clustering[&quot;cluster&quot;] = clusters.labels_print(&#x27;unique:&#x27;, customer_clustering[&quot;cluster&quot;].unique())customer_clustering.head()unique: [3 1 0 2]mean median max min membership_period cluster0 4.833333 5.0 8 2 47 31 5.083333 5.0 7 3 47 32 4.583333 5.0 6 3 47 33 4.833333 4.5 7 2 47 34 3.916667 4.0 6 1 47 3 클러스터링 결과 분석 회원2 그룹은, 회원기간이 짧지만, 사용횟수가 많은 그룹 회원1 그룹은, 기간도 짧고 이용률도 낮음 회원0,3은 회원기간이 길다. 그룹3이 회원기간은 길지만, 이용률은 0보다 낮다. 이렇게 회원 그룹별로 차이가 발생하는것을 파악하고, 어느그룹인지에 따라 다른 정책적용이 가능하다!!! 1234567891011121314151617클러스터링 결과를 분석하자customer_clustering.columns = [&quot;월평균값&quot;,&quot;월중앙값&quot;, &quot;월최댓값&quot;, &quot;월최솟값&quot;,&quot;회원기간&quot;, &quot;cluster&quot;]customer_clustering.groupby(&quot;cluster&quot;).count() 월평균값 월중앙값 월최댓값 월최솟값 회원기간cluster 0 1334 1334 1334 1334 13341 763 763 763 763 7632 846 846 846 846 8463 1249 1249 1249 1249 1249customer_clustering.groupby(&quot;cluster&quot;).mean()월평균값 월중앙값 월최댓값 월최솟값 회원기간cluster 0 5.524239 5.375187 8.745877 2.687406 14.8433281 3.054713 2.888598 4.756225 1.653997 9.2634342 8.054608 8.039598 10.009456 6.160757 7.0721043 4.677494 4.671337 7.232986 2.153723 36.915933 클러스터링 결과를 바탕으로 탈퇴회원의 경향을 파악 그룹0은, 골고루 분포 그룹1은, 탈퇴회원만 존재 그룹2는, 초기 가입고객으로 보이며 초반 의욕적인모습 그룹3은, 2보다는 낮지만, 안정적인12345678910customer_clustering = pd.concat([customer_clustering, customer], axis=1)customer_clustering.groupby([&quot;cluster&quot;,&quot;is_deleted&quot;],as_index=False).count()[[&quot;cluster&quot;,&quot;is_deleted&quot;,&quot;customer_id&quot;]]cluster is_deleted customer_id0 0 0 7851 0 1 5492 1 1 7633 2 0 8274 2 1 195 3 0 12306 3 1 19 routine_flag: 정기적 비정기적 사용고객 여부 그룹0과 그룹3이 가장 정기적으로 사용함12345678910customer_clustering.groupby([&quot;cluster&quot;,&quot;routine_flg&quot;],as_index=False).count()[[&quot;cluster&quot;,&quot;routine_flg&quot;,&quot;customer_id&quot;]]cluster routine_flg customer_id0 0 0 2281 0 1 11062 1 0 4973 1 1 2664 2 0 525 2 1 7946 3 0 27 3 1 1247 클러스터링 가시화12345678910111213from sklearn.decomposition import PCAX = customer_clustering_scpca = PCA(n_components=2)pca.fit(X)x_pca = pca.transform(X)pca_df = pd.DataFrame(x_pca)pca_df[&quot;cluster&quot;] = customer_clustering[&quot;cluster&quot;]import matplotlib.pyplot as plt%matplotlib inlinefor i in customer_clustering[&quot;cluster&quot;].unique(): tmp = pca_df.loc[pca_df[&quot;cluster&quot;]==i] plt.scatter(tmp[0], tmp[1]) 헬스장 사용빈도 예측6개월간 DataSet 준비 다음달의 이용횟수 예측을 위해 테이터를 준비1234567891011121314# 고객별 사용횟수uselog[&quot;usedate&quot;] = pd.to_datetime(uselog[&quot;usedate&quot;])uselog[&quot;연월&quot;] = uselog[&quot;usedate&quot;].dt.strftime(&quot;%Y%m&quot;)uselog_months = uselog.groupby([&quot;연월&quot;,&quot;customer_id&quot;],as_index=False).count()uselog_months.rename(columns=&#123;&quot;log_id&quot;:&quot;count&quot;&#125;, inplace=True)del uselog_months[&quot;usedate&quot;]uselog_months.head()연월 customer_id count0 201804 AS002855 41 201804 AS009013 22 201804 AS009373 33 201804 AS015315 64 201804 AS015739 7 현재월 기준, 1개월전~6개월 data(사용빈도)를 차례로 묶어서, 다음달의 예측값으로 활용하자12345678910# 6개월치 datayear_months = list(uselog_months[&quot;연월&quot;].unique())print(year_months)predict_data = pd.DataFrame()print(predict_data.head())[&#x27;201804&#x27;, &#x27;201805&#x27;, &#x27;201806&#x27;, &#x27;201807&#x27;, &#x27;201808&#x27;, &#x27;201809&#x27;, &#x27;201810&#x27;, &#x27;201811&#x27;, &#x27;201812&#x27;, &#x27;201901&#x27;, &#x27;201902&#x27;, &#x27;201903&#x27;]Empty DataFrameColumns: []Index: [] 1234567891011121314151617181920212223242526272829303132333435363738394041# 직전달 6개월치의 이용횟수를 이번달 기준으로 도출하여 mergefor i in range(6, len(year_months)): tmp = uselog_months.loc[uselog_months[&quot;연월&quot;]==year_months[i]] tmp.rename(columns=&#123;&quot;count&quot;:&quot;count_pred&quot;&#125;, inplace=True) #print(tmp)#연월 customer_id count_pred#18532 201810 AS002855 3 #break for j in range(1, 7): #print(&quot;i-j:&quot;, (i-j)) #6-1 =&gt; 6-7 #print(year_months[i-j]) tmp_before = uselog_months.loc[uselog_months[&quot;연월&quot;]==year_months[i-j]] del tmp_before[&quot;연월&quot;] # 직전달의 결과를 저장 tmp_before.rename(columns=&#123;&quot;count&quot;:&quot;count_&#123;&#125;&quot;.format(j-1)&#125;, inplace=True) tmp = pd.merge(tmp, tmp_before, on=&quot;customer_id&quot;, how=&quot;left&quot;) #print(tmp) #break #break predict_data = pd.concat([predict_data, tmp], ignore_index=True)print(predict_data.head())print(predict_data.tail())연월 customer_id count_pred count_0 ... count_2 count_3 count_4 count_50 201810 AS002855 3 7.0 ... 5.0 5.0 5.0 4.01 201810 AS008805 2 2.0 ... 7.0 8.0 NaN NaN2 201810 AS009373 5 6.0 ... 7.0 4.0 4.0 3.03 201810 AS015233 7 9.0 ... 5.0 7.0 7.0 NaN4 201810 AS015315 4 7.0 ... 6.0 3.0 3.0 6.0[5 rows x 9 columns] 연월 customer_id count_pred ... count_3 count_4 count_539685 201903 TS995853 8 ... NaN NaN NaN39686 201903 TS998593 8 ... 9.0 9.0 9.039687 201903 TS999079 3 ... 6.0 6.0 4.039688 201903 TS999231 6 ... 5.0 5.0 4.039689 201903 TS999855 4 ... 4.0 4.0 5.0 null 제거123predict_data = predict_data.dropna()predict_data = predict_data.reset_index(drop=True)predict_data.head() Feature 추가 특징이 되는 변수를 추가: 회원유지기간(period) 12345678910111213141516171819202122232425predict_data = pd.merge(predict_data, customer[[&quot;customer_id&quot;,&quot;start_date&quot;]], on=&quot;customer_id&quot;, how=&quot;left&quot;)predict_data.head()연월 customer_id count_pred count_0 count_1 count_2 count_3 count_4 count_5 start_date0 201810 AS002855 3 7.0 3.0 5.0 5.0 5.0 4.0 2016-11-011 201810 AS009373 5 6.0 6.0 7.0 4.0 4.0 3.0 2015-11-012 201810 AS015315 4 7.0 3.0 6.0 3.0 3.0 6.0 2015-07-013 201810 AS015739 5 6.0 5.0 8.0 6.0 5.0 7.0 2017-06-014 201810 AS019860 7 5.0 7.0 4.0 6.0 8.0 6.0 2017-10-01predict_data[&quot;now_date&quot;] = pd.to_datetime(predict_data[&quot;연월&quot;], format=&quot;%Y%m&quot;)predict_data[&quot;start_date&quot;] = pd.to_datetime(predict_data[&quot;start_date&quot;])from dateutil.relativedelta import relativedeltapredict_data[&quot;period&quot;] = Nonefor i in range(len(predict_data)): delta = relativedelta(predict_data[&quot;now_date&quot;][i], predict_data[&quot;start_date&quot;][i]) predict_data[&quot;period&quot;][i] = delta.years*12 + delta.monthspredict_data.head()연월 customer_id count_pred count_0 count_1 count_2 count_3 count_4 count_5 start_date now_date period0 201810 AS002855 3 7.0 3.0 5.0 5.0 5.0 4.0 2016-11-01 2018-10-01 231 201810 AS009373 5 6.0 6.0 7.0 4.0 4.0 3.0 2015-11-01 2018-10-01 352 201810 AS015315 4 7.0 3.0 6.0 3.0 3.0 6.0 2015-07-01 2018-10-01 393 201810 AS015739 5 6.0 5.0 8.0 6.0 5.0 7.0 2017-06-01 2018-10-01 164 201810 AS019860 7 5.0 7.0 4.0 6.0 8.0 6.0 2017-10-01 2018-10-01 12 Regression 예측 다음달 이용횟수를 예측하는 모델을 구축12345678910111213predict_data = predict_data.loc[predict_data[&quot;start_date&quot;]&gt;=pd.to_datetime(&quot;20180401&quot;)]from sklearn import linear_modelimport sklearn.model_selectionmodel = linear_model.LinearRegression()X = predict_data[[&quot;count_0&quot;,&quot;count_1&quot;,&quot;count_2&quot;,&quot;count_3&quot;,&quot;count_4&quot;,&quot;count_5&quot;,&quot;period&quot;]]y = predict_data[&quot;count_pred&quot;]X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y)model.fit(X_train, y_train)print(model.score(X_train, y_train))print(model.score(X_test, y_test))0.603400210812480.6089792828788805 모델에 기여하는 변수를 확인 : 가장 직전달의 영향도가 가장 큼1234567891011coef = pd.DataFrame(&#123;&quot;feature_names&quot;:X.columns, &quot;coefficient&quot;:model.coef_&#125;)coeffeature_names coefficient0 count_0 0.3335051 count_1 0.2038082 count_2 0.1656993 count_3 0.1721004 count_4 0.0850765 count_5 0.0540276 period 0.078326 임의 사용자의 사용패턴에 대해 다음달의 이용횟수를 예측하자1234567x1 = [3, 4, 4, 6, 8, 7, 8]x2 = [2, 2, 3, 3, 4, 6, 8]x_pred = [x1, x2]result = model.predict(x_pred)print(result)[3.8379106 2.02046272]","categories":[{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/categories/data-scientist/"},{"name":"Practice","slug":"data-scientist/practice","permalink":"https://jukyellow.github.io/categories/data-scientist/practice/"}],"tags":[{"name":"데이터 분석","slug":"데이터-분석","permalink":"https://jukyellow.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D/"},{"name":"파이썬","slug":"파이썬","permalink":"https://jukyellow.github.io/tags/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"},{"name":"Panadas","slug":"panadas","permalink":"https://jukyellow.github.io/tags/panadas/"},{"name":"DataFrame","slug":"dataframe","permalink":"https://jukyellow.github.io/tags/dataframe/"},{"name":"K-means","slug":"k-means","permalink":"https://jukyellow.github.io/tags/k-means/"},{"name":"Sklearn","slug":"sklearn","permalink":"https://jukyellow.github.io/tags/sklearn/"},{"name":"LinearRegression","slug":"linearregression","permalink":"https://jukyellow.github.io/tags/linearregression/"}]},{"title":"시계열 분석(통계분석 기법)-Part1","slug":"statistics-time-series","date":"2021-04-11T21:52:28.000Z","updated":"2021-05-14T22:22:39.148Z","comments":true,"path":"2021/04/12/statistics-time-series/","link":"","permalink":"https://jukyellow.github.io/2021/04/12/statistics-time-series/","excerpt":"","text":"개요: 통계학 기반 시계열 예측 모델의 이론과 실습을 통해 알아보자, 특히 ARIMA모델 사용법을 익혀보자 강좌: [K-MOOC강의] 시계열분석 기법과 응용, http://www.kmooc.kr/courses/course-v1:POSTECHk+IMEN677+2020_2/video ARIMA 모형을 이용한 비정상적 시계열 예측 Part2 목차1234Week1. 시계열 평활기법Week2. ARMA 모형Week3. ARMA 모형의 식별 및 예측Week4. 비정상적 시계열 Week1. 시계열 평활기법강좌소개: 수평적 패턴, 추세 패턴, 계절성이 포함된 패턴 -&gt; 시계열 이동평균법과 이중 이동평균법시계열 분석 하나의 변수에 대한 시간에 따른 관측치를 시계열 또는 시계열 데이터라함 시계열 분석의 목적: 시계열의 특성(추세, 계절성 등)을 요약하고 시간에 따른 패턴(자기 상관성 등)분석: 시간에 따른 패턴을 바탕으로 모형화하고 미래값을 예측 회귀모형과 달리 다른 변수를 도입하지 않고 자신의 변수의 과거 패턴이 미래에도 계속된다는 가정하에과거값을 바탕으로 미래값 예측 시계열 패턴은 수평/추세/계절성이 복합된 것으로 간주 시계열 분석 개요 평활화 모형: 이동평균, 지수평활, 원터스 모형, 분해법 정상적 ARMA 모형: AR모형, MA모형, ARMA 모형 비정상적 모형: ARIMA 모형, 계절성 ARIMA 모형 오차 이분산 모형: ARCH모형, GARCH 모형 다변량 시계열: 벡터회귀 모형(VAR) 상태공간모형 이동 평균법 이동편균(Moveing Averatge): 매 시점에서 직전 N개 데이터의 평균을 산출하여 평활치로 사용 단순 이동 평균: 시계열 데이터가 수평적 패턴인 경우 이중 이동평균: 추세 패턴을 따르는 경우 사용 단순 이동 평균법 시계열 데이터가 수평적 패턴인 경우 사용 시점 t+1에서의 이동평균(산술평균) 시점 T에서 시점T+1의 값 예측(한 단계이후 예측) N 클수록 평활 효과가 큼 (N이 작으면 최근 추세 반영, 크면 평평해지는 효과 큼) 이중 이동 평균법 시계열이 선형 추세를 갖는다고 가정하자: Xt = c + bt + at 단순 이동편균 추세는 늦게 따라감(gap이 생김)이를 보정하기 위해 이중 이동평균을 활용 이중 이동 평균: 이동선이 여러 변수의 영향을 받으면 그 변수만큼 데이터 확보가 필요…? 예측성능 척도 예측오차: 특정 시점에서 다음 시점을 예측하고 다음 시점의 실제값과 비교하여 예측 오차를 산출 Et,1 = Xt+1 - Ft,1 평균제곱오차(MSE), 제곱근 평균제곱오차(RMSE-기본단위와 같음), 평균절대오차(MAD), 평균절대 퍼센트오차(MAPE) 지수평활법과 이중 지수평활법지수평활법과 이중 지수평활법과 지수평활법(Exponential Smoothing) : 평활치를 구하는데 전체 데이터를 사용, 시간에 따른 다른 가중치를 줌, 과거로 갈수록 지수적으로 감소하는 가중치 사용 단순 지수평활: 시계열 데이터가 수평적인 패턴인 경우이중 지수평활: 추세패턴을 따르는 경우홀트 모형(Holt`s Model) 추세패턴을 따라는 경우 단순 지수평활법 시계열 데이터가 수평적 패턴인 경우 St = Axt + a(1-a)Xt-1 + a(a-a)^2Xt-2 … 시점 t+1에서 지수평활치: St+1 = Axt+1 + (1-a)St 평홯상수 (0&lt;aa)작을수록 평활효과가 큼 최근 추세를 반영하여 예측코자 하면 큰 a를 사용하고 저네 평균으로 예측코자 하면 작은 a를 사용 이중 지수평활법 시계열 데이터가 추세 패턴을 따르는 경우 단순 지수평활치의 기대치와 시계열 기대치간에는 격차가 존재: 이를 보정하기 위해 이중 지수평활을 활용: St(2) = aSt + (1-a)S(2)t-1 홀트 및 윈터스 모형 추세와 계절성을 고려한 지수 평활 모형 계절성 고려 모형 추세와 계절성이 있는 시계열에 적용 윈터스(Winters) 모형: 홀트 모형에 계절성(seansonality)를 추가 반영하여 확장, 가법모형과 승법모형이 있음 분해법(Decomposition): 추세와 계절성을 분해한 후 예측시 다시 결합, 가법모형과 승법모형이 있음 윈터스 모형 홀트 모형에 계절성(분기/월별 변형 및 주기성을 띄는..)을 추가반영하여 확장시킴 가법모형(더해지는) 승법(곱해지는)모형 분해법 가법적 모형: Xt = Bt + St + … = 0 승법적 모형: Xt = Bt X St X … = m 분해법에 의한 예측 절차 중심 이동 평균으로 평활치를 산출추세 제거계절성 지수 산출계절성 제거 시계열 산출회귀모형으로 추세 추정추세 및 계절성 지수 결합하여 예측치 산출 분해법(승법적 모형) Week2. ARMA 모형정상적 시계열분석 정상성의 조건, 자기상관함수 정상적 시계열 실제 시계열은 추세,계절성을 포함하는 비정상적 것이 많으나, 우선 정상적 시계얼의 성질을 알아본다. 비정상적 시계열은 적절한 변환을 통해 정상적 시계열로 바꿀수 있다. 강 정상성: 시계열에 대해 동일한 결합확률분포를 가질때 정상성을 갖는 시계열이라고 함. 기대치가 시간에 따라 일정, 분산이 일정, 자기공분산 또는 자기상관계수가 시간간격에만 의존 약 정상성: 시계열의 기대치가 시간에 따라 일정하고, 임의의 두 시점 자기공분산이 시간간격에만 의존 유한할 때 약저상성 결합확률본포가 다변량 정규분포를 따를때, 시계열분석에서는 약 정상성을 가정함 자기상관함수 자기 공분산: 시계열의 시간에 따른 연관 패턴을 자기공분산으로 요약 시차 K의 자기공분산 자기상관함수(ACF) autocorrelation Function(ACF) 시차 K의 자기상관계수: p(k) = Corr[Zt,Zt-k] = Cov[Z,Zt-k]/VAR[Zt] = r(k)/r(0) 비교적 단순한 형태의 정상적 시계열 모형을 주로 다루며 ACF로 모형을 식별함 정상적 시계열 편자기상관함수(PACF), AR 표현방식과 MA 표현방식 편자기상관함수(PACF, Partial) 정상적 시계열의 형태를 식별하는데, ACF외에 PACF정보를 활용함 PACF란 시차가 K인 두 값들 간의 상관계수가 중간 시점들의 값들이 이미 설명한 이후 추가적인 영향만을 고려하여 고안 시계열 표현방식 자기회귀(AR: autoregressive) 표현방식: 시점 t의 값(Zt)을 과거 시점의 값들을 이용한 회귀식으로 표현자기회귀 과정 이동평균(MA: Moving average) 표현방식: 시점t의 값(Zt)를 현재와 과거시점의 백색잡음으로 표현이동평균 과정이라고도 함 후향 연산자 사용: Zt-k = B^k Zt, k = 1,2,… AR모형 및 MA모형의 표현 및 설질 규명ARMA 모형 AR모형: AR표현방식이며 유한 시차로 구성, AR(1)은 시차 1변수 포함 MA모형: MA표현방식이며 유한 시차로 구성, MA(1) 시차1의 백색잡음 포함 ARMA모형: AR/MA 방식이 결합된 형태, ARMA(1,1)은 시차1의 변수와 시차1의 백색잡음 포함 AR모형 AR(1) 모형: 가장 단순한 상태: Zt = Theta Zt-1 + At AR(2) 모형: 시차 2변수까지 포함 AR(p) 모형: 시차 p의 변수까지 포함 MA모형 MA(1): 시차1의 백색잡음 포함, ARMA 모형의 표현과 성질 이해ARMA 모형 ARMA(1,1) : AR(1)과 MA(1)의 복합형태시점 t 값은 시점 t-1의 값… 그리고 시점 t와 t-1의 오차항으로 생성된다. ARMA(p,q) 모형: 시차 P까지 변수와 시차 q까지 오차항을 포함 ARMA(1,1) 모형의 ACF: 지수적으로 감소하는 패턴 ARMA(1,1) 모형의 PACF: 지수적으로 감소하는 패턴 ACF,PACF 분석 ACF: p&gt;=q +1 일때, ACF는 AR(p)모형과 유사하게 0으로 떨어진다.: p&lt;q일때, 처음 p-q값은 별개의 값을 갖고 이후 AR(p)모형과 유사하게 0으로 떨어진다. PACF: p&gt;q+1 일때는, PACF는 처음 p-q값은 별개의 값을 갖고, 이후 MA(q)모형과 유사하게 0으로 떨어진다.: p&lt;=q 일때, 처음부터 MA(q)모형과 유사하게 0으로 떨어진다. Week3. ARMA 모형의 식별 및 예측ARMA 모형의 식별 시차 판정 ARMA 모형의 식별 1단계: 시계열 그래프-&gt;정상성 여부 판정-&gt;비정상성은 추세제거/계절성제거/분산안정화등 통해 정상시계열 변환 2단계: 시계열 데이터에 대한 표본 ACF/PACF를 산출하고 정상성 여부 확인(비정상인경우 1단계 반복) 3단계: (모형의 식별) 표본 ACF및 표본 PACF를 다양한 ARMA모형의 이론적 ACF및 PACF 비교하여 ARMA모형의 p,q를 구한다. 4단계: (모형의 추정) 3단계에서 얻은 모형에 대한 계수들을 추정하고 잔차(residual)를 구한다. 5단계: (모형의 검증) 잔차가 백삭잡음을 따르는지 검정한다. 잔차가 백색잡음을 따르면 단계3의 모형이 제대로 식별되었으며, 아니면 다를 차수 p,q를 구한후 과정 반복 표본 ACF 및 표본 PACF 표본 ACF 산출(단계 2): 표본 분산 = 1/n 시그마 (Zi-Zbar)^2: 시차 K 표본자기공분산: 표본 ACF = 표본자기공분산/표본분산표준오차 … 표본 PACF 산출시차별 PACF는 ACF로 표현되므로 ACF를 추정하여 표본 PACF를 구한다. ARMA 모형의 이론적 ACF와 PACF 패턴 정상적 시계열의 이론적 ACF/PACF와 모형의 실제 시계열 표본 ACF/PACF와 비교 ARMA모형의 파라미터 추정을 위한 최우추정법시계열 모형 추정방법 최소자승법: AR모형의 경우 가능 비선형 최소자승법: ARMA모형에 적용 최우 추정법(maximum likeihood estimation): 오차항이 서로 독립인 정규분포를 따르므로 우도함수(likeihood function)을 유도하여 이를 최대로 하는 모형개수를 추정.: ARMA모형의 경우 정확한 우도함수 도출이 어렵고 초기치에 대한 가정이 필요: 조건있는 우도함수-임의로 초기치를 가정하여 사용: 조건없는 우도함수: 과거의 초기치를 후방예측(backcasting)하여 사용 최우추정법 ARMA모형의 경우 관측치가 독립이 아니므로, 우도함수 구성어려움 대신 백색잡음이 서로 독립임을 활용하여 우도함수를 구함 조건있는 우도함수 ARMA(p,q)모형에서 산출, 백색잡음을 최소화하는.. 조건제곱합… 조건없는 우도함수 과거값 예측에 후방예측 사용, 시간축을 반대방향으로 생각 ARMA모형의 추정 추정치&gt;표준오차&gt;t-value, p-value 확인 ARMA모형의 검증 모형의 오차항이 평균0, O^2의 정규분포를 따르는 백색잡음이라 가정하고 있기때문에, 이에 대한 검증이 필요 잔차에 대하여 다음을 확인: 정규성(정규확률도표): 등분산성 및 패턴유무(잔차 산점도): 랜덤성(ACF/PACF로 시차별 상관계수가 모두 0인지 확인, 포트만토 검정…) 최소평균오차 기반의 ARMA 모형 예측치 유도시계열 예측 최소 평균제곱오차 예측치: Fn,k = 시점 n에서 K시점 이후(즉, n+k시점) 시계열 예측치 과거 시계열 관측치의 선형결합으로 예측 평균제곱오차(MSE): 미래의 실제값과 예측값의 차이의 제곱을 최소화(조건부 기대치와 동일) 예측오차: K시점 이후 예측오차 분산은 조건부 분산과 동일 ARMA모형 예측 예측식: 시점 n까지의 과거데이터로부터 매리 시점 예측은 조건부 기대치 사용 예측오차 분산: 예측구간이 필요한 경우 사용 Week4. 비정상적 시계열비정상적 시계열 모형화를 위한 ARIMA모형비정상 시계열 추세, 계절성이 포함되는 경우 정상성을 만족하지 못한다. 비정상적 판단방법: 시계열 그래프 시각적 판단, ACF가 시차에 대해 매우 서서비 감소하는 패턴, 단위근 검정(단위근이 존재하면 비정상적 시계열) 대응방안: 차분을 통해 정상적 시계열로 변환, 함수변환 통해 분산 안정화, 분해법으로 추세및 계절성 제거 ARIMA 모형 차분: 1차 차분: 인근한 두 값의 차이를 산출, 2추차분-1차차분에 추가로 차분을 적용… 차수 d 누적 시계열: d차 차분후 시계열이 정상적일때, 원 시계열을 차수 d 누적 시계열 I(d)로 표기 ARIMA 모형 정의: 차수 d 누적시계열, d차분후 시계열이 처음으로 정상적일때, 원 시계열을 차수 d 누적시계열이라고 하고 I(d)로 표기: 원시계열(ZtARIMA(p,d,q)) -&gt; d차 차분 -&gt; 차분시계열(WtARMA(p,q)) 계절성을 반영한 ARIMA 모형의 이해계절성 시계열 추세는 차분으로 제거될수 있으나 계절성은 여전히 남아있을수 있다. 계절성은 별도로 처리필요 일반적으로 시계열은 비계절성 ARIMA모형과 계절성 ARIMA모형이 복합된 형태이다. 계절성 ARIMA 모형 계절성 차분: 계절성 주기 S (월별 S=12, 분기별 S=4) 계절성이 있는 경우 단순(비계절성) 차분으로 정상화 되지 않음 1차 계절성 차분: 인근한 두 계절 값의 차이를 산출 계절성 ARIMA 모형의 유도 예측: 주기 S=12 갖는 추세없는 월별 시계열 고려: 매년 1월 데이터들만 볼때 MA(1) 모형을 따른다고 하자: 인글월의 오차항간에 상관관계가 있으므로 새로운 모형이 필요: 이 모형은 비계절성 MA(1)과 계절성 MA(1)이 결합된 형태 ARMA(0,1)X(0,1)12또는 ARIMA(0,0,1) X (0,0,1)12라고 함 표기: 계절성 ARIMA(p,d,q) X (P,D,Q)s 모형의 식별 및 추정 (단계1) 시계열도를 그려보고 추세 및 계절성 존재여부를 판단 (단계2) 아래 사항 고려 적절히 차분: 추세는 없고 계절성이 있는 경우, 해당 주기에 대한 계절성 차분: 추세가 있고 뚜렷한 계절성이 없는 경우, 선형추세가 있는 경우, 1차차분, 곡선형태의 추세가 있는 경우 차분전에 함수변환 시도: 추세와 계절성이 있는 경우, 우선 계절성 차분을 실시하고 추세를 다시 검토, 추세가 여전히 남아있는 경우 1차 차분 추가 실시하고 (단계3) 차분 시계열에 대한 AFC와 PACF를 바탕으로, p,q, P,Q를 결정: 비계절성 계수인 p,q는 ARMA모형의 경우와 동일한 요령으로 결정: 계절성 계수 P,Q는 주기의 배수에 나타나는 ACF와 PACF의 패턴을 보고 결정 (단계4) 모형 파라미터 추정방법 (단계5) 잔차 검정 실시 ACF산출 예 차분 시계열 산출, 분산, 자기 공분산 계산, ACF 계산 비정상 검정을 위한 단위근 검증단위근 검정 단위근 검정은 통계적 검정을 통해 시계열의 정상성 여부를 판정: 대표적인 단위근 검정은 ADF(augmented Dickey-Fuller) 검정: 모든 정상적 시계열은 고차원의 AR모형으로 근사될수 있다고 가정 단위근 풀이 및 예 생략…","categories":[{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/categories/data-scientist/"},{"name":"Note","slug":"data-scientist/note","permalink":"https://jukyellow.github.io/categories/data-scientist/note/"}],"tags":[{"name":"강의노트","slug":"강의노트","permalink":"https://jukyellow.github.io/tags/%EA%B0%95%EC%9D%98%EB%85%B8%ED%8A%B8/"},{"name":"시계열분석","slug":"시계열분석","permalink":"https://jukyellow.github.io/tags/%EC%8B%9C%EA%B3%84%EC%97%B4%EB%B6%84%EC%84%9D/"},{"name":"time series","slug":"time-series","permalink":"https://jukyellow.github.io/tags/time-series/"},{"name":"ARMA","slug":"arma","permalink":"https://jukyellow.github.io/tags/arma/"},{"name":"ARIMA","slug":"arima","permalink":"https://jukyellow.github.io/tags/arima/"}]},{"title":"도커 기본 명령어","slug":"docker-command2","date":"2021-04-09T22:33:17.000Z","updated":"2021-05-04T22:02:59.882Z","comments":true,"path":"2021/04/10/docker-command2/","link":"","permalink":"https://jukyellow.github.io/2021/04/10/docker-command2/","excerpt":"","text":"개요: 도커를 사용하여 API 서버/서비스를 개발(ubuntu)하는 과정에서 사용했던 도커 기본 명령어를 정래해 본다. 기본 설치(centos)는 이전 블로그 참고 도커란? 가상화 기술(하나의 HW를 SW적으로 분할하여 마치 여러개의 독립된 HW에서 동작시키는것과 같이 리소스를 공유하는 기술)의 하나로,컨테이너 단위로 구동되고, 컨터이너(SW적으로 분리된 독립된 공간) 안에 OS에서부터 application Layer까지 stack 형식으로 쌓아 올림으로써,필요한 구성요소를 손쉽게 다운로드/실행하는 방식으로 동작시키는 기술이다. 목차12345678910111213141516A. 도커 기본 명령어1. 버전 확인2. 이미지 확인3. 컨테이너 목록 확인4. 컨테이너 구동5. 컨테이너 IP 확인6. 컨테이너 종료7. 컨테이너/이미지 삭제8. 컨테이너 내부 접속9. 컨테이너/Host간 파일 복사10. 도커 이미지 빌드 11. 도커 run 명령어 옵션B. DockerfileC. Docker 실행(쉘로 관리) 도커 기본 명령어버전확인1docker -v 도커 이미지 목록1docker images 도커 컨테이너 목록1docker ps -a 컨테이너 구동1docker run --rm --publish 8001:80 -it nginx 컨테이너 ip/port 확인12docker exec CONTAINER_ID ip addr show eth0docker port 도커ID 컨테이너 종료1docker stop 컨테이너ID(5555b7dd1385) 도커 컨테이너 모두 삭제, 이미지 삭제12345678910- 컨테이너 하나 삭제docker rm 컨테이너ID- 권한 없어서 전체삭제는 안됨?docker rm $(docker ps -a -q)- 이미지 삭제docker rmi [이미지명]- dangling image remove1) docker rmi -f $(docker images -f &quot;dangling=true&quot; -q)2) docker image prune(docker api 1.25이상 지원, -a를 붙이면 전체삭제함으로주의!(-a없이 사용하자)) 컨테이너 내부접속1docker exec -it 98a6916d8759 /bin/bash 컨테이너/Host 파일복사12341) 호스트-&gt;컨테이너 : docker cp [host 파일경로] [container name]:[container 내부 경로]docker cp testWebApp.war 9492a62f43d4:/usr/local/tomcat/webapps2) 컨테이너-&gt;호스트 : docker cp [container name]:[container 내부 경로] [host 파일경로]docker cp 445a0ba19eea:/usr/local/tomcat/conf/server.xml c:/101_dimg 도커 이미지 빌드12- docker build -t [이미지명] .docker build -t nginx . 도커 이미지 다운로드/구동12docker pull tomcat:8docker run -d -i -t -p 8081:8080 tomcat:8 도커 컨테이너 접속(stdout?)1docker attach 도커ID 컨테이너 로그 tail1234- log tail docker logs -f 컨테이너ID- 옵션: --tail=5 (최근5줄만 보기?)- log tail 종료: Ctrl+p -&gt; Ctrl+q 연속으로 입력(바로 종료하면 컨테이너 죽음 주의!) 컨테이너 실행 페라미터 전달1docker run -e &quot;SPRING_PROFILES_ACTIVE=dev&quot; -p 8080:8080 -t springio/gs-spring-boot-docker 도커 run 명령어 주요 옵션1234567891014)도커 run 명령어 상세docker run -d -i -t -p 9001:9001 nginx_microsvc:latestdocker run &lt;옵션&gt; &lt;이미지 이름, ID&gt; &lt;명령&gt; &lt;매개 변수&gt;-d: --detach=false: Detached 모드입니다. 보통 데몬 모드라고 부르며 컨테이너가 백그라운드로 실행됩니다.-i: --interactive=false: 표준 입력(stdin)을 활성화하며 컨테이너와 연결(attach)되어 있지 않더라도 표준 입력을 유지합니다. 보통 이 옵션을 사용하여 Bash에 명령을 입력합니다-t: --tty=false: TTY 모드(pseudo-TTY)를 사용합니다. Bash를 사용하려면 이 옵션을 설정해야 합니다. 이 옵션을 설정하지 않으면 명령을 입력할 수는 있지만 셸이 표시되지 않습니다.-p: --publish=[]: 호스트에 연결된 컨테이너의 특정 포트를 외부에 노출합니다. 보통 웹 서버의 포트를 노출할 때 주로 사용합니다. Dockerfiledockerfile CMD 명령어 CMD [“nginx”, “-g”, “daemon off;”] CMD [“&lt;실행 파일&gt;”, “&lt;매개 변수1&gt;”, “&lt;매개 변수2&gt;”] 셸 없이 바로 실행할 때 매개 변수 설정하기: daemon off : nginx.conf에 daemon off;로 설정했으므로 Nginx 웹 서버를 foreground로 실행합니다. 도커 파일 예제12345FROM openjdk:8-jdk-alpineVOLUME /tmpARG JAR_FILECOPY msap-zuul-server-0.1.0.war app.warENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.war&quot;] dockerfile 이미지 빌드docker build -t msap-config-server . 실행12341) bridge 모드docker run --publish 9000:9000 -it msap-config-server (bridge 모드: 네트웍 격리)2) host 모드docker run --net=host --publish 9000:9000 -it msap-config-server (host 모드: host와 IP공유) 도커 실행 쉘로 관리법12345678910111213141) 해당 컨테이너 종료docker stop $(docker ps --filter &#x27;name=facenet-server&#x27; -q)2) 이미지 삭제docker rm $(docker ps --filter &#x27;name=facenet-server&#x27; -a -q)docker rmi -f $(docker images -f &quot;dangling=true&quot; -q)3) 빌드docker build -t facenet-server .4) 실행docker run --name ai-hsgd-verfiy-server \\ --publish 8312:8312 \\ --net=host \\ -d \\ -it \\ -v ai-hsgd-verfiy-server-logs:/logs ai-hsgd-verfiy-server","categories":[{"name":"MSA","slug":"msa","permalink":"https://jukyellow.github.io/categories/msa/"},{"name":"Docker","slug":"msa/docker","permalink":"https://jukyellow.github.io/categories/msa/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jukyellow.github.io/tags/docker/"},{"name":"docker install","slug":"docker-install","permalink":"https://jukyellow.github.io/tags/docker-install/"},{"name":"Root Dir","slug":"root-dir","permalink":"https://jukyellow.github.io/tags/root-dir/"},{"name":"Centos","slug":"centos","permalink":"https://jukyellow.github.io/tags/centos/"},{"name":"MSA","slug":"msa","permalink":"https://jukyellow.github.io/tags/msa/"}]},{"title":"리눅스/유닉스 명령어 모음2","slug":"linux-command2","date":"2021-04-01T20:42:22.000Z","updated":"2021-04-01T21:47:55.350Z","comments":true,"path":"2021/04/02/linux-command2/","link":"","permalink":"https://jukyellow.github.io/2021/04/02/linux-command2/","excerpt":"","text":"개요 : 유닉스(솔라리스) OS에서 Java Application을 운영하면서 사용했던 명령어들을 두번째로 정리해본다. 서비스 운영자로서 기본 유닉스 사용법 정리는 이전 블로그 참고 목차123456781. nslookup2. hostname3. telnet/ping/tracert4. 터미널 ssh 접속5. Shell 특수문자와 2&gt;&amp;1의 의미6. 파일 생성시간 기준으로 찾기/삭제하기7. SWAP 메모리 추가8. 웹서버 설정(Sun ONE)과 WAS Timeout설정 nslookup DNS에 등록된 domain name을 ip addresss 반환 1nslookup www.google.com hostname hostname 확인 방법 123$ cat /etc/hosts127.0.0.1 localhost127.0.1.1 storycompiler 관련문제: Java 프로세스에서 UnKnownHostException 발생시, DNS에서 host이름으로 IP를 못찾는것! 해결방법: 로컬 캐시(/etc/hosts에 정보 기입) 및 networking restart 참고: https://storycompiler.tistory.com/118 12$ sudo /etc/init.d/networking restart[ ok ] Restarting networking (via systemctl): networking.service. telnet/ping/tracert telnet : 텔넷 접속 명령어 활용: 방화벽 오픈(Ip/port) 확인용으로 주로 사용, 방화벽이 열리지 않은 경우 접속 실패 발생 1telnet ip port ping: target ip로 네트워크 상태 확인(패킷 전송 및 응답 수신) 활용 : 주로 상대방 서버의 live상태를 체크 및 방화벽 오픈 여부 목적으로 사용 1ping ip 옵션 tracert (리눅스 traceroute): ip 라우팅 경로 추적 활용 : 내부망/외부망이 분리된 경우, 인터넷망에서 접속 실패/다운로드 실패시에 라우팅 경로를 확인하여 문제를 찾아볼수 있다. 1tracert ip 기타(windows): 접속 사이트별 응답정보 확인용으로 fiddler 설치 및 확인 : https://www.telerik.com/fiddler 터미널 SSH 접속1ssh -p 15022 user@123.123.123.123 Shell 특수문자와 2&gt;&amp;1의 의미 $! : 최근 백그라운드 작업의 프로세스 번호 활용: 프로세스 pid를 저장해두고 stop shell에서 kill pid로 죽일때 사용가능1echo $! &gt; $HOME/bin/pid/stop_pid.sh 2&gt;&amp;1 : 2(standard err)를 &amp;1(standard output과 같은 파일로) &gt;(redirect한다) 설명: 표준에러를 표준출력 파일과 같은 stream(파일)로 write한다. 1234java -Dtype=TEST com.test.java test.cfg &gt; test.out 2&gt;&amp;1 &amp; #java프로세스를 실행하는데 test.out파일로 표준출력을 write함. #그리고 표준에러도 표준출력과 같은 파일로 쓰고, java프로세스는 백그라운드(&amp;)로 실행 #표준에러를 파일에 쓰도록 했기때문에, 화면(screen)에 Exception내용이 찍히지 않음 파일 생성시간 기준으로 찾기/삭제하기 참고: https://joont.tistory.com/129 방법: find의 -newer 옵션(지정한 파일의 날짜보다 이후에 수정된 파일을 찾아주는 옵션) 활용12345678910111) touch -t 20160501 begin (우분투는 yyyyMMddhh24mi 까지 입력해야 됨?)2-1) find . -newer begin -print&gt; begin 파일보다 이후에 수정된 파일을 검색합니다. 즉, 2016년 5월 1일 이후의 파일을 검색하게 되는것이죠.2-2) find . ! -newer begin -print&gt; find의 부정연산자를 사용하면 2016년 5월 1일 이전의 파일도 검색 가능합니다.2-3) touch -t 20160530 end, find . -newer begin -a ! -newer end -print&gt;2016년 5월 1일부터 2016년 5월 30일 사이에 수정된 파일을 검색하는 방법입니다.3) find . -newer begin -a ! -newer end | wc -l&gt; 개수 구하기4) find . -newer begin -a ! -newer end -exec rm -f &#123;&#125; \\;&gt; 삭제하기 (*주의: 반드시 . 현재디렉토리 기준으로 찾기바람, /를 쓰면 최상위 경로가 됨) SWAP 메모리 추가(1G-&gt;3G할때) 참고1: https://htst.tistory.com/32 크게 두가지 방식 partition(디스크 할당) or SWAPFILE(swap용 big file추가) 처리가 있음 partition이 존재할때 swapfile을 추가하여 간단하게 스왑메모리를 추가할수 있음. 참고2: https://steps4great.tistory.com/7 –swapfile 만들기 1234sudo fallocate -l 2G /swapfile → swapfile 생성sudo chmod 600 /swapfile → root 사용자만 사용할 수 있도록 권한 변경sudo mkswap /swapfile → 스왑메모리로 변경sudo swapon /swapfile → 스왑메모리 활성화 재부팅시 swap메모리 남아있게 설정 12sudo vi /etc/fstab입력내용 → /swapfile swap swap default 0 0 스왑메모리 제거 1234sudo vi /etc/fstab → 자동마운트 내용 제거 및 주석처리sudo swapoff -v /swapfilesudo swapoff on /swapfilesudo rm -r /swapfile 웹서버 설정과 WAS Timeout설정웹서버(Sun ONE) 설정파일 /opt/sunone61/https-xxx/config/object.conf : URI 패턴을 등록하고 해당하는 요청일때 필터링 기능 동작 /opt/sunone61/https-xxx/config/server.xml : 웹서버 포트등 설정123&lt;Object name=&quot;weblogic_do&quot; ppath=&quot;*.do&quot;&gt; Service fn=&quot;wl_proxy&quot; WebLogicCluster=&quot;xxx.xxx.xxx.xxx:9820,xxx.xxx.xxx.xxx:9820&quot; DynamicServerList=&quot;OFF&quot; Idempotent=&quot;ON&quot; WLIOTimeoutSecs=&quot;3600&quot; KeepAliveEnabled=&quot;false&quot; CookieName=&quot;NLPS_ADMIN_JSESSIONID&quot;&lt;/Object&gt; 설정파일(object.conf) 옵션 설명 WLIOTimeoutSecs (HungServerRecoverSecs) : WLS로 request를 보내고 response를 받기 위해 대기하는 시간, default 300초 KeepAliveEnabled : Plug-in과 WLS의 연결을 지속할 것인지 여부를 결정 client request를 처리한 후 WLS와의 연결을 닫아버릴 것인지 연결된 상태로 두었다가 다음 요청이 들어왔을 때 재사용할 것인지 설정Default =&gt; true(Netscape and Microsoft IIS) &amp; ON (Apache) Idempotent (ON/OFF) : WebLogic서버로 부터 request전송시 에러가 발생하거나, 서버로부터 결과를 기다리는 중에 위에 정의된 WLIOTimeoutSecs 시간 초과되어서 에러 발생시 요청을 다시 보낼 것인가를 지정서버와 연결은 되었는데 그 이후에 에러가 발생 하였을 경우 해당 옵션이 ON이면 다시 연결을 시도하고, 요청을 보내게 되므로 중복 요청의 가능성이 있다. OFF권장 WAS Timeout 설정 세션 Timeout 설정: 웹로직 콘솔: 배치-&gt;프로젝트명-&gt;구성 &gt; “세션시간초과” 항목 서버 xml파일 web.xml : /WEB-INF 하위, web.xml의 경우에 단위는 분이다. 123&lt;session-config&gt; &lt;session-timeout&gt;60&lt;/session-timeout&gt;&lt;/session-config&gt; weblogic.xml : 단위는 초이다. 123456&lt;session-descriptor&gt; &lt;session-param&gt; &lt;param-name&gt;TimeoutSecs&lt;/param-name&gt; &lt;param-value&gt;3600&lt;/param-value&gt; &lt;/session-param&gt;&lt;/session-descriptor&gt;","categories":[{"name":"Linux","slug":"linux","permalink":"https://jukyellow.github.io/categories/linux/"}],"tags":[{"name":"nslookup","slug":"nslookup","permalink":"https://jukyellow.github.io/tags/nslookup/"},{"name":"telnet","slug":"telnet","permalink":"https://jukyellow.github.io/tags/telnet/"},{"name":"hostname","slug":"hostname","permalink":"https://jukyellow.github.io/tags/hostname/"},{"name":"tracert","slug":"tracert","permalink":"https://jukyellow.github.io/tags/tracert/"},{"name":"ssh접속","slug":"ssh접속","permalink":"https://jukyellow.github.io/tags/ssh%EC%A0%91%EC%86%8D/"},{"name":"파일생성시간 삭제","slug":"파일생성시간-삭제","permalink":"https://jukyellow.github.io/tags/%ED%8C%8C%EC%9D%BC%EC%83%9D%EC%84%B1%EC%8B%9C%EA%B0%84-%EC%82%AD%EC%A0%9C/"},{"name":"2>&1","slug":"2-1","permalink":"https://jukyellow.github.io/tags/2-1/"},{"name":"웹서버설정","slug":"웹서버설정","permalink":"https://jukyellow.github.io/tags/%EC%9B%B9%EC%84%9C%EB%B2%84%EC%84%A4%EC%A0%95/"}]},{"title":"AI 이론 정리노트","slug":"ai-theory-note","date":"2021-04-01T20:32:11.000Z","updated":"2021-04-29T21:19:58.255Z","comments":true,"path":"2021/04/02/ai-theory-note/","link":"","permalink":"https://jukyellow.github.io/2021/04/02/ai-theory-note/","excerpt":"","text":"개요 딥러닝/머신러닝 이론를 작성해보자! 진척률(2021.04.30): 2% 목차123456789101112131415161718192021222324252627282930313233343536A. 개론 1. 신경망의 역사 2. 머신러닝과 딥러닝의 차이 3. 신경망 구조 4. 오류 역전파 알고리즘 5. 활성화 함수 6. 성능측정 및 평가B. NLP 7. 자연어 처리 개요 8. 자연어 전처리 및 성능측정/평가 9. Word2Vec, FastText, 통계적?... 10. RNN/LSTM, Seq2Seq 11. Attention 모델 12. Transformer 모델(Bert) 13. GPT-3 모델C. 머신러닝 모델 14. SVC 15. 배깅과 부스팅 16. 랜덤포레스트 17. XgBoost, AdaBoost 등 18. 앙상블 19. 성능측정, 평가D. 이미지 모델 20. CNN 개요 21. CNN 다양한 버전들 22. 안면인식 23. OCRE. 통계모델 24. 통계모델 개요 25. AR/ARIMA 모형F. AI와 수학/통계학 26. 기술통계(평균,분산,표준편차,표준정규분포등) 27. 28. 29. 30. 통계모델ARIMA 모형 참고(이론노트): https://jukyellow.github.io/2021/04/12/statistics-time-series/ 참고(실습-비트트레이딩): https://jukyellow.github.io/2021/04/24/bit-trade-competition1/","categories":[{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Note","slug":"ai/note","permalink":"https://jukyellow.github.io/categories/ai/note/"}],"tags":[{"name":"강의노트","slug":"강의노트","permalink":"https://jukyellow.github.io/tags/%EA%B0%95%EC%9D%98%EB%85%B8%ED%8A%B8/"},{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/tags/ai/"},{"name":"Lecture","slug":"lecture","permalink":"https://jukyellow.github.io/tags/lecture/"},{"name":"Kaist","slug":"kaist","permalink":"https://jukyellow.github.io/tags/kaist/"},{"name":"note","slug":"note","permalink":"https://jukyellow.github.io/tags/note/"},{"name":"머신러닝","slug":"머신러닝","permalink":"https://jukyellow.github.io/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/"}]},{"title":"빅데이터 이론/분석 Part2","slug":"빅데이터-이론-분석-part2","date":"2021-04-01T20:31:47.000Z","updated":"2021-04-18T20:49:02.791Z","comments":true,"path":"2021/04/02/빅데이터-이론-분석-part2/","link":"","permalink":"https://jukyellow.github.io/2021/04/02/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9D%B4%EB%A1%A0-%EB%B6%84%EC%84%9D-part2/","excerpt":"","text":"[온라인 강좌 강의노트] K-MOOC 강좌명: [집콕]빅데이터의 세계, 원리와 응용 빅데이터 이론/분석 Part1 진척률(2021.04.17): 10% 목차12345675. 군집분석6. 연관규칙7. 회귀분석과 예측8. 기계학습과 인공신경망9. 기계학습과 의사결정나무10. 텍스트 분석 기법11. 데이터 시각화의 원리 5주차 데이터 군집화 방법 군집분석이란? 정의: 유사한 특성을 가진 데이터 집단으로 그룹화하는 기법 구분: 자율학습(목표 변수가 없음), 비지도 학습에 해당 목표: 데이터 이해를 돕기위해, 특성 값이 유사한 레코드들의 모임으로 세분화 유형: 계층적 클러스터링(Single Linkage method?), 비계층적(K-means), 모델기반(Kohonen network) 계층적 병합 군집화 N개의 군집 시작 -&gt; 가장 근접한 2개의 레코드를 군집 병합 -&gt; 매 단계에서 가장 거리가 짧은 2개 군집 병합 레코드간의 거리 측정: 유클리드 거리, 만하탄 거리, 군집간의 거리 측정: 최단거리/최대거리/평균거리/중심거리 등 단일(최단) 연결법(Single Linkage method): 각 군집에 속하는 임의의 두 개체들 사이의 거리중 최단거리로 정의하여 유사성이 큰 군집을 묶어나가는 방법 계층적 군집화의 장단점:: (장점) 군집의 수 명시 필요없음, 군집화가 자동수행, 덴드로그램 도출 이해용이: (단점) 데이터가 클 경우 거리행열 계산 부담, 극단치에 민감, 비안정성(데이터 재구성시 상이한 결과 나타날수 있음) 비계층적 군집분석 원하는 군집의 수(K)를 사전에 명시하고, 군집들 내부의 분산을 최소화하도록 각 사례를 K개의 군집중 하나에 할당하는 기법 ex: k-means 절차: 클러스터링 수 K결정 -&gt; 최초 군집 기준값 결정-&gt; 군집분류-&gt; 군집 기준값 설정-&gt;군집재분류&lt;-&gt;군집기준값변경-&gt;최종 클러스터 도출 군집분석의 장단점 및 활용 장점: 데이터에 대한 사전 지식 필요없음, 모든 형태의 데이터에 적용가능 단점: 각 변수에 대한 가중치를 결정하거나 거리 정의 방법에 따라 결과 차이 가능, 초기 클러스터 수에 민감, 결과 해석 어려움 활용: (데이터 이해제고) 데이터 마이닝 초기작업에 유용, 세부집단 지식 없어서 전체 이해 하기 어려운 경우 탐색가능: 텍스트 마이닝 적용시, 유사 문서 군집화 유용: 마케팅의 고객 세분화 등 다양한 분양에 적용 실습1~2 보험청구 데이터 유사그룹 생성, 보험사기 정보 활용 분류모형 구축: (독립변수) 신고장소, 경찰신고접수, 청구타입, 청구금액, 총결찰 신고접수, (목적변수) 사기여부 6주차연관관계 분석이란?연관관계 분석이란? 대용량으 데이터로부터 규칙을 찾아내는 기법 장바구니 분석(구매 물품사이의 관계를 알아본다) 연관성이 많은 상품들을 그룹화하는 클러스터링의 일종 연관규칙의 도출 if A then B 형태의 규칙으로 표시 후보 규칙 생성 연관 규칙 분석의 예 식료품점 판매 물품들에 대해 생성된 연관규칙을 그래프로 나나탠 분석결과 연관 규칙 예측력의 측정 빈도수 기반으로 연관정도를 정량하 화기 위한 지표: 지지도/신뢰도/향상도 지지도(support) Pr(A and B): 전체 거래중 A와 B를 포함하는 거래의 비율 산식: support = A와 B를 포함하는 거래수 / 전체 거래수 전체적인 거래 규모에 대한 값, 값이 클수록 자주 발생하는 거래, 규칙의 중요성에 대한 척도 신뢰도(Confidence) 정의: Pr(B|A) = Pr(A&amp;B)/P(A) 산식: A와 B를 포함하는 거래수/A의 포함 거래수 X를 구매한 경우, 이중에서 얼마나 항목 Y를 구매로 이어지는지를 의미 값이 클수록 X구매시 Y구매율이 높음 규칙의 신뢰성에 대한 척도 향상도(Lift) 졍의: Pr(B/A)/Pr(B) = Pr(A&amp;B) / Pr(A)Pr(B) 산식: Lift = (“A”-&gt;”B” 발생 확률)/(A발생확률)(B발생확률) 연관규칙이 임의 추측보다 얼마나 더 예측력을 갖는지 평가 일반적으로 리프트값이 1보다 크면 예측력이 있다고 간주 연관과계 실습1~3 문제: 장바구니 분석 변수: 고객ID, 지불금액, 지불방법, 성별, 주택소유 여부, 수입, 나이, 채소과일 Week7 회귀분석과 예측 회귀분석이란","categories":[{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/categories/data-scientist/"},{"name":"Note","slug":"data-scientist/note","permalink":"https://jukyellow.github.io/categories/data-scientist/note/"}],"tags":[{"name":"빅데이터","slug":"빅데이터","permalink":"https://jukyellow.github.io/tags/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/"},{"name":"Data Analysis","slug":"data-analysis","permalink":"https://jukyellow.github.io/tags/data-analysis/"},{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/tags/data-scientist/"},{"name":"K-MOOC","slug":"k-mooc","permalink":"https://jukyellow.github.io/tags/k-mooc/"},{"name":"강의노트","slug":"강의노트","permalink":"https://jukyellow.github.io/tags/%EA%B0%95%EC%9D%98%EB%85%B8%ED%8A%B8/"}]},{"title":"구글 Colab Jupyter Notebook 사용 팁","slug":"google-colab-tip","date":"2021-03-22T20:57:17.000Z","updated":"2021-03-22T22:00:42.092Z","comments":true,"path":"2021/03/23/google-colab-tip/","link":"","permalink":"https://jukyellow.github.io/2021/03/23/google-colab-tip/","excerpt":"","text":"keras framework로 2년간 google colab과 google drive를 이용해 작업시 사용하던 내용을 정리해본다. 목차123456781. Google Drive file download-upload2. Colab file upload/download3. Colab tensorflow/keras downgrade4. Colab file handling5. Colab utility install6. Colab github 프로젝트 연동7. Colab upload 오류 대처8. Colab에 주식관련 Lib 설치(Ta-Lib) Google drive file download-uploadfile download123456789101112131415161718192021222324252627282930313233343536373839#구글 드라이브에서 다운로드from google.colab import authauth.authenticate_user()from googleapiclient.discovery import builddrive_service = build(&#x27;drive&#x27;, &#x27;v3&#x27;)import iofrom io import BytesIO from googleapiclient.http import MediaIoBaseDownloadTEMP_PATH = &#x27;/tmp/&#x27;def gcp_download(file_name, key): #3. 모델 다운로드 #https://drive.google.com/open?id=1TlvbayGRCjAI6bOZrUYMmv6g6b95rnRM request = drive_service.files().get_media(fileId=key) downloaded = io.BytesIO() downloader = MediaIoBaseDownload(downloaded, request) done = False while done is False: status, done = downloader.next_chunk() if status: print(&quot;Download %%%d%%.&quot; % int(status.progress() * 100)) print(&quot;Download Complete!&quot;) downloaded.seek(0) with open(TEMP_PATH + file_name, &#x27;wb&#x27;) as f: f.write(downloaded.read())# 사용법 : 다운로드시 사용할 파일명, 파일key 정보만 있으면 됨!down_file_name = &#x27;201912_purcon_gd.csv&#x27;gcp_download(down_file_name, &#x27;1q-E4K439JJBV2HnqgbibHMhmNOAHO11v&#x27;)#pickle 파일 다운로드 및 로딩import picklegd_tokenizer_name = &#x27;gd_tokenizer_350K4_ALL.pickle&#x27;gcp_download(gd_tokenizer_name, &#x27;15hcUEPYB-el1oNctRrhLqObuFKVvXJSV&#x27;)#loadingwith open(TEMP_PATH + gd_tokenizer_name, &#x27;rb&#x27;) as handle: gd_tokenizer = pickle.load(handle) file upload1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556!pip install -U -q PyDrivefrom pydrive.auth import GoogleAuthfrom pydrive.drive import GoogleDrivefrom google.colab import authfrom oauth2client.client import GoogleCredentialsgcp_drive = Nonedef doGoodleDriveAuth(): # 1. Authenticate and create the PyDrive client. auth.authenticate_user() gauth = GoogleAuth() print(&#x27;gauth:&#x27;,gauth) gauth.credentials = GoogleCredentials.get_application_default() gcp_drive = GoogleDrive(gauth) print(&#x27;gcp_drive:&#x27;, gcp_drive) return gcp_drive# PyDrive reference:# https://googledrive.github.io/PyDrive/docs/build/html/index.htmldef gcp_upload(file_path, w_file_name): try: if gcp_drive == None: drive = doGoodleDriveAuth() # 특정 폴더 안으로 파일 삽입 uploaded = drive.CreateFile(&#123;&#x27;title&#x27;: w_file_name&#125;) #, &quot;parents&quot;: [&#123;&quot;kind&quot;: &quot;drive#fileLink&quot;,&quot;id&quot;: &#x27;jukyellow@gmail.com&#x27;&#125;]&#125;) uploaded.SetContentString(w_file_name) uploaded.SetContentFile(file_path + w_file_name) uploaded.Upload() print(&#x27;Uploaded file with ID &#123;&#125;&#x27;.format(uploaded.get(&#x27;id&#x27;))) return uploaded.get(&#x27;id&#x27;) except Exception as e: print(&#x27;gcp_upload err:&#x27;, e)# 사용법# 먼저, 파일을 100M단위로 분할 압축(100M 이상일때 한번에 안올라가는 문제있어서)!zip -s 100M -o TextCNN_EarayStop.zip ./TextCNN_EarayStop.h5# 루프돌면서 분할 파일 업로드(나중에 다시 합칠때는 다운로드 받고 압축푼다음 합칠수 있음)try: for idx in range(9): if idx == 0: div_name = &quot;TextCNN_EarayStop.zip&quot; else: div_name = &quot;TextCNN_EarayStop.z0&quot; + str(idx) gcp_upload(&quot;./&quot;, div_name) #gcp root경로에 저장됨except Exception as e : print(&#x27;e:&#x27;, e)# 분할파일을 다시 내려받고 합칠때model_name_early_stop = &#x27;TextCNN_EarayStop_350K4.h5&#x27; #gcp_download(model_name_4bu, &#x27;1T2Es7AO2FTYuMaq2A8-9Tc_g_mUKhitP&#x27;) # temp 경로에 다운로드gcp_download(&#x27;TextCNN_EarayStop_350K4.zip&#x27;,&#x27;1RD9VCeLwKmZrZCP8SRRjwA4ADGPzZcZi&#x27;)gcp_download(&#x27;TextCNN_EarayStop_350K4.z01&#x27;,&#x27;17RPrQiuPyx5eUATEX5FYMBSxKcao6X5w&#x27;)gcp_download(&#x27;TextCNN_EarayStop_350K4.z02&#x27;,&#x27;1NrR7sHeVEcqlJT4bSAspx3RsTvbpiZkH&#x27;)gcp_download(&#x27;TextCNN_EarayStop_350K4.z03&#x27;,&#x27;1nI0yli3HLCSRF3RVWTNgQCUQ0thhmviv&#x27;)#...# 분할파일 머지 및 압축해제!cat /tmp/TextCNN_EarayStop_350K4.z* &gt; /tmp/TextCNN_EarayStop_Mer.zip!unzip /tmp/TextCNN_EarayStop_Mer.zip Colab file upload/downloadcolab file upload12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 1. 직접 업로드( files.upload())from google.colab import files#파일업로드창 출력uploaded = files.upload()#업로드한 파일정보 출력for fn in uploaded.keys(): print(&#x27;Upload file &quot;&#123;name&#125;&quot; with length &#123;length&#125; bytes&#x27;.format(name=fn, length=len(uploaded[fn])))#읽어서 사용im = imread(&quot;output.jpg&quot;)# 2.google drive업로드 후 로딩 방법#2-1) 파일을 열어서 라인단위로 읽어서 저장하는 방법#Pre-Trained data를 사용(find-tune)embeddings_index = &#123;&#125;# driver codefrom google.colab import driveimport osdrive.mount(&#x27;/content/gdrive&#x27;)f = open(os.path.join(&#x27;/content/gdrive/My Drive&#x27;, &#x27;glove.6B.100d.txt&#x27;))for line in f: values = line.split() word = values[0] coefs = np.asarray(values[1:], dtype=&#x27;float32&#x27;) embeddings_index[word] = coefsf.close()print(&#x27;Found %s word vectors.&#x27; % len(embeddings_index))# 2-2) dataPath 및 Gensim 이용해서 파일을 읽어오는 방법# 2-2-1)from gensim.test.utils import datapath, get_tmpfilefrom google.colab import drivedrive.mount(&#x27;/content/gdrive&#x27;)glove_file = datapath(&#x27;/content/gdrive/My Drive/glove.6B.100d.txt&#x27;) xy = np.loadtxt( glove_file , delimiter=&#x27;,&#x27;, dtype=np.float32) # 2-2-2)from gensim.test.utils import datapath, get_tmpfilefeature_data = datapath(&#x27;/content/gdrive/My Drive/AI/kaggle/&#x27; + &#x27;300features_40minwords_10text&#x27;) # 2-3) google drive경로에서 읽는 방법# 2-3-1) imagefrom google.colab import drivedrive.mount(&#x27;/content/gdrive&#x27;)from matplotlib.pyplot import imreadim = imread(&quot;/content/gdrive/My Drive/NLP-Lab/output.jpg&quot;)# 2-3-2)txt readfrom google.colab import drivedrive.mount(&#x27;/content/gdrive&#x27;)#csv data readxy = np.loadtxt(&#x27;/content/gdrive/My Drive/data-01-test-score.csv&#x27;, delimiter=&#x27;,&#x27;, dtype=np.float32) #문자열인 경우 dtype=np.str#google driave root 경로: /content/gdrive/My Drive/x_data = xy[:, 0:-1]y_data = xy[:, [-1]]#단 chunk_size 초과로 오류발생 가능.. colab file download1234567891011121314# A. pandas data 다운로드import pandas as pdpd.DataFrame(err_vec).to_csv(&quot;/tmp/preporcessing_case6.csv&quot;)from google.colab import filesfiles.download(&quot;/tmp/preporcessing_case6.csv&quot;)# B. Numpy 다운로드import numpya = numpy.asarray([ [1,2,3], [4,5,6], [7,8,9] ])numpy.savetxt(&quot;foo.csv&quot;, a, delimiter=&quot;,&quot;)from google.colab import filesfiles.download(&quot;파일명&quot;) Colab tensorflow/keras downgrade123456789101112131415# tensorflow 1.x대 적용방법 1%tensorflow_version 1.ximport tensorflow as tf# 버전확인print(tf.__version__)# tensorflow 1.x대 적용방법2!pip install tensorflow==1.14.0# 특정 버전 설치? : pip3 install tensorflow-gpu==1.15.2# keras version downgrade!pip uninstall keras!pip install keras==2.1.2import kearsprint(__keras.version__) Colab file handling1234567891011121314151617# 디렉토리 조회! ls -alrt /content/# 파일 move!mv /tmp/facenet_keras.h5 /content# 파일 삭제!\\rm -rf /content/origin_data# 디렉토리 생성!mkdir /content/origin_data# 압축관련 설치!apt-get install zip unzip#압축 100M이하로!!zip -s 100M -o TextCNN_GCN_10bu.zip ./TextCNN_GCN_10bu.h5# -r:하위경로 모두 포함하여 압축, 현재경로에 zip파일 만들기(대상은 절대경로로)!zip -r dataset_zip.zip /content/dataset# 압축풀기 : 한글깨짐 방지: -O cp949!unzip -O cp949 /tmp/00_Total.zip!rm -rf /tmp/00_Total.zip Colab utility install12!pip uninstall google-api-python-client -y!pip install google-api-python-client==1.7.3 Colab github 프로젝트 연동123456789101112!git clone https://github.com/philipperemy/keras-attention-mechanism.git!ls -alrt!cd keras-attention-mechanismimport numpy as npfrom attention_utils import get_activations, get_datanp.random.seed(1337) # for reproducibilityfrom keras.models import *from keras.layers import Input, Dense, merge Colab upload 오류 대처1234567891011121314151617# 오류내용 : RedirectMissingLocation: Redirected but the response is missing a Location: header.#버전 확인#!pip list#httplib2 0.17.1#google-api-python-client 1.7.12 # 방안 : downgrade (https://github.com/tokland/youtube-upload/issues/293)# !pip3 install google-api-python-client==1.7.3 oauth2client==4.1.2 progressbar2==3.38.0 httplib2==0.15.0!pip uninstall google-api-python-client -y!pip uninstall oauth2client -y!pip uninstall progressbar2 -y!pip uninstall httplib2 -y!pip install google-api-python-client==1.7.3!pip install oauth2client==4.1.2!pip install progressbar2==3.38.0!pip install httplib2==0.15.0 Colab 주식관련 Lib 설치(Ta-Lib)1234567# (2020) https://stackoverflow.com/questions/49648391/how-to-install-ta-lib-in-google-colaburl = &#x27;https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files&#x27;!wget $url/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb!wget $url/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb!dpkg -i libta.deb ta.deb!pip install ta-libimport talib","categories":[{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Note","slug":"ai/note","permalink":"https://jukyellow.github.io/categories/ai/note/"}],"tags":[{"name":"Colaboratory","slug":"colaboratory","permalink":"https://jukyellow.github.io/tags/colaboratory/"},{"name":"google colab","slug":"google-colab","permalink":"https://jukyellow.github.io/tags/google-colab/"},{"name":"google drive","slug":"google-drive","permalink":"https://jukyellow.github.io/tags/google-drive/"},{"name":"Jupter notebook","slug":"jupter-notebook","permalink":"https://jukyellow.github.io/tags/jupter-notebook/"},{"name":"drive file download","slug":"drive-file-download","permalink":"https://jukyellow.github.io/tags/drive-file-download/"},{"name":"keras","slug":"keras","permalink":"https://jukyellow.github.io/tags/keras/"}]},{"title":"헥소 검색 엔진 최적화","slug":"hexo-search-engine-optimization","date":"2021-03-16T21:29:30.000Z","updated":"2021-03-17T20:24:55.904Z","comments":true,"path":"2021/03/17/hexo-search-engine-optimization/","link":"","permalink":"https://jukyellow.github.io/2021/03/17/hexo-search-engine-optimization/","excerpt":"","text":"참고: https://youngjunsung.github.io/2019/12/06/hexo-blog-SEO/ 플러그인 설치 목록12345npm install --save hexo-auto-canonicalnpm install --save hexo-autonofollownpm install --save hexo-generator-feednpm install --save hexo-generator-seo-friendly-sitemapnpm install --save hexo-generator-robotstxt _config.xml123456789101112131415161718nofollow: enable: true exclude: - exclude1.com - exclude2.comfeed: type: rss2 path: rss2.xml limit: 20sitemap: path: sitemap.xml tag: true category: truerobotstxt: useragent: &quot;*&quot; allow: - / sitemap: https://jukyellow.github.io/sitemap.xml tag 삽입 head.ejs 파일의 head 태그 안에 삽입 12&lt;!-- ejs --&gt;&lt;%- autoCanonical(config, page) %&gt; 구글/네이버 웹마스터 등록구글 search console 구글 search console : sitemap.xml 제출 네이버 네이버 웹마스터 도구: 사이트 URL 제출 및 동작체크 구글 애널리스틱 sitemap 정상적으로 제출후, 접속 통계정보 확인 가능","categories":[{"name":"Blog, PT","slug":"blog-pt","permalink":"https://jukyellow.github.io/categories/blog-pt/"},{"name":"Hexo","slug":"blog-pt/hexo","permalink":"https://jukyellow.github.io/categories/blog-pt/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://jukyellow.github.io/tags/hexo/"},{"name":"search engine optimization","slug":"search-engine-optimization","permalink":"https://jukyellow.github.io/tags/search-engine-optimization/"},{"name":"SEO","slug":"seo","permalink":"https://jukyellow.github.io/tags/seo/"},{"name":"검색엔진노출","slug":"검색엔진노출","permalink":"https://jukyellow.github.io/tags/%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84%EB%85%B8%EC%B6%9C/"},{"name":"robots.txt","slug":"robots-txt","permalink":"https://jukyellow.github.io/tags/robots-txt/"},{"name":"sitemap.xml","slug":"sitemap-xml","permalink":"https://jukyellow.github.io/tags/sitemap-xml/"}]},{"title":"빅데이터-이론-분석-Part1","slug":"빅데이터-이론-분석-part1","date":"2021-03-15T22:08:40.000Z","updated":"2021-03-16T20:14:11.316Z","comments":true,"path":"2021/03/16/빅데이터-이론-분석-part1/","link":"","permalink":"https://jukyellow.github.io/2021/03/16/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9D%B4%EB%A1%A0-%EB%B6%84%EC%84%9D-part1/","excerpt":"","text":"[온라인 강좌 강의노트] K-MOOC 강좌명: [집콕]빅데이터의 세계, 원리와 응용 1주차빅데이터란 빅데이터 분석: 귀납적(경험-&gt;정보) 비즈니스 인텔리젠스(1990년대말): 데이터-&gt;기업정보활용: 데이터웨어하우스/OLAP, 데이터 마이닝 데이터 분석과정: 데이터확인&gt;수집&gt;저장(Hadoop,NoSQL)&gt;처리&gt;분석(통계,마이닝)&gt;표현 빅데이터 주요특징 기술적요소/전략적요소/인적요소 기술적요소: 데이터(정형/비정형), 수집/처리/저장, 분석/지식추출 전략적요소: 디지털 transformation&gt;Data Technology 활용기획&gt;빅데이터 분석 활용기회탐색&gt;활용시나리오 도출 인적요소: CDC(Chief Data Officer), Data Scientists, 빅데이터 팀, 교육 빅데이터와 인공지능 귀납(사례,데이터분석)에 의한 지식획득 가능성(빅데이터)-&gt;딥러닝 학습 빅데이터가 제공하는 기회 의사결정의 질 제고, 운영효율 제고, 새로운 가치 창출(BM발굴) 데이터 분석과정 데이터(Source인식) &gt; 수집(ETL,클롤링) &gt; 저장(Hadoop,NoSQL) &gt; 처리 &gt; 분석(통계,마이닝,머신러닝) &gt; 표현(가시화) 2주차빅데이터 활용의 핵심 성공요인 분석을 위한 기획능력 필요 분석 시나리오 수립이 어려운 이유: 도메인 지식부족, 수집/저장/분석 기술능력 부족, 어떤 결과가 도출가능한지 이해부족 기획능력 향상방법: 요소기술 이해, 가치에 대한 인식, 성공사례 분석 활용사례 1 독감예보 서비스(구글 검색어 빅데이터로 예측): 어떤 데이터: 검색어 조회수: 어떻게 분석: 빈도를 계산: 어떤 가치 제공: 독감 예보 SNS를 활용한 영화 흥행 수익 예측: 어떤 데이터: SNS상의 비정형 Text 데이터: 어떻게 분석: 텍스 마이닝(감정분석, 오피니언 분석): 어떤 가체 제공: 경영/투자자의 의사결정 자료 빅데이터 분석을 통한 심야버스 노선 정책지원: 어떤 데이터: 서울시민 전화통화 기록: 어떻게 분석: 기술통계(평균,표준편차,빈도): 어떤 가치: 시민편익, 수익보장 빅데이터 기반 고객의 소리분석 시스템을 통한 서비스 혁신: 어떤 데이터: 고객 음성 데이터(STT:speech to text): 어떻게 : 텍스트 마이닝: 어떤 가치: 고객 중심 경영 활용사례 2 데이터 마이닝을 활용한 신용평가 시스템 구축 (국민은행): (생각1) 기업의 재무제표 지표값과 회사의 부도여부 간의 상관성: (생각2) 부도난 회사의 패턴을 머신러닝으로 모델링(부도패턴 예측) -&gt; 부도예측시스템 구축: 어떤 데이터: 기업 데이터(재무, 비재무): 어떻게 분석: 통계기법, 인공지능 기법 모형구축: 어떤 가치 제공: 기업 심사비용 감축, 의사 결정 지원 빅데이터 분석을 활용한 감사정보 시스템 구축 빅데이터 분석을 활용한 탈세 및 범죄 예방시스템 구축: 어떤 데이터: 납세,SNS데이터: 어떻게 분석: 데이터 마이닝, 사회연결망 분석: 어떤 가치 제공: 재정 수입에 기여, 탈세 예방 효과 빅데이터 분석 기획1,2 문제해결 &gt; 목표와 방법 &gt; 확보계획 분석 기획 목적:: 분석대상 발굴 및 구체화, 확보 역량, 분석역량, 운영관리 체계 정규화, 의사결정문화 정착: 데이터/분석역량/프로세스/문화/ICT 거버넌스등 전반에 걸친 해결방안 수립 분석 기획의 단계: 분석기회 발굴 =&gt; 분석기회 구체화 =&gt; 마스터 플랜 수립: 분석 기회 발굴: 문제 정의/필요성/목표 정의: 분석 기회 구체화: 목표달성 방법 구체화, 수행절차 적용방법/기술 정의: 마스터 플랜수립: 로드맵/일정계획, 분석 거버넌스 체계 필요 분석 기회발굴: 톱다운(전사비즈모델분석), 바틈업(대상프로세스선정/분석), 벤치마킹 분석 기회 구체화: 분석 체계/과정 구체화, 활용시나리오 구체적 정의: 분석기회 구조화: 묵표가치, 유저스토리 형식 정의, 목표가치 지표화, 분석질문 정의: 분석방안 구체화: 체계/과정 구체화, 전체분석세트 및 관계도출, 데이터 정의 분석 경제성 평가: 활용시나리오정의: 프로세스 지능화/변화 발생 마스터 플랜 수립: 전략적 우선순위, 로드맵 수립(우선순위 평가, 분석적용 범위/방식 고려): 분석 과제 우선순위 평가: 중요도, 경제성(ROI), 실행용이성 고려: 단계적 구현 로드맵 수립:: 일정계획: 세부 일정 3주차분석을 위한 데이터들 정형 데이터: 고정된 필드에 저장된 데이터, 설계자에 의해 형태가 정해짐 비정형 데이터: 문서/그림/영상… 분석대상 데이터의 예: 텍스트분석-&gt;핵심단어, 주요토픽/이슈, 감정(긍정/부정): 웹: Html&gt;Tagging&gt;분석: SNS: 사용자반응&lt;–게시글 크롤링: 로그데이터: 방문시간/횟수/접근정보/관심상품…: 센서데이터/사진(이미지)/동영상 빅데이터의 수집 데이터수집: 데이터소스 데이터 자동수집, 저장/변환/통합 수집과정의 중요성: 정확한 데이터가 필요/분석목적 고려 내부데이터/외부데이터 수집방법(ETL) : 수집/변환/적재 외부 데이터 수집방법: 크롤링(스크래핑)- Textom, (데이터 저장) 데이터베이스란(데이터 저장) 데이터모델링이란(E-R모델링)(데이터 분석) 데이터 웨어하우스란? DW: DB(응용프로그램목적), DW(적절한조합-&gt;지식변환 목적-&gt;의사결정지원) DW정의: 주제중심/통합/시간성/비휘발성 자료 집합 DW특징: 주제/데이터중심, 비휘발성(읽기중심), 시간성(역사성) 데이터 마트(Mart):: 데이터 웨어하우스와 사용자 사이의 중간층에 위치: 하나의 주제 하나의 부서 중심 DW: DW가 도매상이면, DT는 소매상: DW-&gt;DT로 데이터 복제 구성: 운영/보관data -&gt; 자료 추출/변환 -&gt; 메타데이터&lt;-&gt; DW-&gt;DT -&gt; 분석도구/OLAP OLAP(On-Line Analytical Processing) 다차원 데이터 구조를 이용하여 다차원의 복잡한 질의를 고속으로 처리하는 데이터 분석기술 온라인 분석처리의 구성요소 : 드립 다운(Drill down)/드립 업, 빅데이터와 비정형 데이터베이스(1) 분산시스템 필요, 비정형 데이터베이스(NoSQL, Hadoop) CAP이론(Consistency-일관성, Availability-가용성, Partiton Tolerance-지속성) 불가능: CAP중 두개를 선택하고 하나를 포기(RDB-C/A, 비정형-P/A, P/C) NoSQL(Not-Only SQL or NoSQL): 규마 확장성, 분산저장, 대용량 구조/반구조적 저장 용이(MongoDB…): key-val(레디스,캐시..), 컬럼(H베이스..), 도큐먼트(몽고DB..), 그래프(Neo4J..) NoSQL 특징: 스키마 없음, 저장방식(값,컬럼,문서,그래프), 탄력성, 부하분산용이, 조회용이 비정형 데이터베이스(2) 하둡(Hadoop)이란? : 대용량 데이터의 분산 저장과 처리가 가능한 자바 기반 오픈소스 프레임워크: 여러개의 컴퓨터를 묶어서 하나의 시스템으로 처리: 하둡 파일 시스템(HDFS), 맵리듀스(분산된 서버 자원으로 쉽게 분석) 데이터 &gt; 맵리듀스(분석처리) &gt; HDFS 주요특징: 대용량 처리에 적합, 클라우드 환경 적합, 장애의 대비, 저렴한 구축비용 구성요소: 파일시스템(HDFS, 64M~128M단위 분산저장/복제/클러스터), 맵리듀스(분산처리계산) 4주차데이터분석 데이터 분석 유형: Descriptive Analysis: 현재상황 이해/사실 파악: Diagnostic Analysis : 현재상황 이해/원인파악: Predictive Analysis: 미래, 또는 결과에 대한 예측: Prescriptibe Analsis: 해결방안 도축 Descriptive 방식: 데이터 요약/정보생성, 사실이해/현황파악, 의사결정 지원: 기술통계, 군집화, 연관규칙, Predictive 방식: 예측모형, 미래/미지의 값 추정: 예측, 분류, Descriptive Analysis 기술통계: 통계기반(평균,최대,최소…) 데이터 속성 요약/파악 군집화: 유사속성 묶어, 군집(Cluster)으로 나누는것 연관규칙: 데이터에 숨어있는 항목간의 관계를 탐색하는 것, 규칙성 도출 Predictive Analysis 예측모형: 과거의 데이터바탕, 관측되지 않은 변수의 미래 값 평가: 예측, 분류 예측모형의 구축 및 활용: Historical Data -&gt; Predictive Alogorithms -&gt; Model -&gt; New data -&gt; predict 기계학습 인공지능기법이자 인공지능에 필요한 지식을 찾는 방법론 지도학습/비지도학습/강화박습 학습용 데이터 구축: 독립변수(t 시점), 종속변수(t+1시점): 기계학습(가중치 초기화&gt;출력값 계산&gt;목표값의 비교)-&gt;교사학습(가중치조정-&gt;과정반복) SPSS SPSS Modeler(ver 17): 데이터 마이닝 도구, 대용량 데이터 처리, 결과 예측모형 도출: 데이터 로딩/변환/정제/모델링/그래프/결촤출력 전과정을 하나의 환경에서 제공, 다양한 알고리즘 보유 데이터 마이닝 데이터내 관계/패턴/규칙 탐색하여 모형화 및 유용한 지식 추출의 일련과정 도입배경: 컴퓨터파워증가, 통계적/기계학습기법 접목/데이터 수집관리능력 향상 수행단계: 샘플링-&gt;정제/전처리-&gt;탐색및변형-&gt;모형화-&gt;보고/시각화-&gt;적용단계 텍스트 마이닝 자연어로 구성된 비정형 Text 데이터에서 패턴/관계를 추출하여 가치정보를 찾아내는 기법 수행단계: 텍스트수집-&gt;전처리(형태소분석 등)-&gt;의미정보변환(불용어/어간처리 등)-&gt;의미정보추출-&gt;패턴경향분석-&gt;정보표현/평가 적용분야: 출시상품 웹반응분석, 고객 VOC분석 마케팅활용","categories":[{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/categories/data-scientist/"},{"name":"Note","slug":"data-scientist/note","permalink":"https://jukyellow.github.io/categories/data-scientist/note/"}],"tags":[{"name":"빅데이터","slug":"빅데이터","permalink":"https://jukyellow.github.io/tags/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/"},{"name":"Data Analysis","slug":"data-analysis","permalink":"https://jukyellow.github.io/tags/data-analysis/"},{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/tags/data-scientist/"},{"name":"K-MOOC","slug":"k-mooc","permalink":"https://jukyellow.github.io/tags/k-mooc/"},{"name":"강의노트","slug":"강의노트","permalink":"https://jukyellow.github.io/tags/%EA%B0%95%EC%9D%98%EB%85%B8%ED%8A%B8/"}]},{"title":"Kaggle-Notebook-Guide","slug":"kaggle-notebook-guide","date":"2021-03-14T04:36:50.000Z","updated":"2021-03-15T01:37:19.816Z","comments":true,"path":"2021/03/14/kaggle-notebook-guide/","link":"","permalink":"https://jukyellow.github.io/2021/03/14/kaggle-notebook-guide/","excerpt":"","text":"Kaggle 사이트에서 머신러닝 개발환경(jupyter notebook)을 제공한다. Kaggle competition에서 제공하는 DataSet은 100G가 넘어가는게 많은데, 캐글 개발환경에서 바로 DataSet 접근이 가능하다. 1주 최대 38시간 GPU 사용이 가능하고, 주마다 Reset된다.(notebook생성할때 어디서 봤는데 다시 못찾겠다;;) 메뉴진입 회원가입 -&gt; Competion -&gt; Summit Predictions -&gt; New Notebook 제약사항 확인일반 제약사항 GPU: 1주 38시간(1주일단위 초기화되어 다시 38시간 사용가능) 20G까지 쓰기 가능 You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using “Save &amp; Run All” GPU 설정 Data 추가 Data접근예제코드 제공 이미 아래와 같이 예제코드 제공하고, 파일count 체크하는 로직을 추가하였다. 123456789101112131415161718192021222324252627# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python# For example, here&#x27;s several helpful packages to loadimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the read-only &quot;../input/&quot; directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directoryimport osf_cnt_map = &#123;&#125;for dirname, _, filenames in os.walk(&#x27;/kaggle/input&#x27;): f_cnt_map[dirname] = len(filenames)# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won&#x27;t be saved outside of the current sessionfor idx, d_name in enumerate(f_cnt_map.keys()): print(&quot;idx:&quot;, idx, &quot; ,d_name:&quot;, d_name, &quot; ,f_cnt:&quot;, f_cnt_map[d_name])print(&quot;---&quot;) prn_cnt = 0for dirname, _, filenames in os.walk(&#x27;/kaggle/input&#x27;): for filename in filenames: print(os.path.join(dirname, filename)) prn_cnt + = 1 if(prn_cnt&gt;=30) break 샘플파일 보기123456- 1. 파일명 확인!ls /kaggle/input/hpa-single-cell-image-classification/test/- 2. 이미지 보기# 이미지 샘플(test-set) 보기!img_array = np.array(Image.open(&#x27;/kaggle/input/hpa-single-cell-image-classification/test/0040581b-f1f2-4fbe-b043-b6bfea5404bb_blue.png&#x27;))plt.imshow(img_array) Label 정보 확인1234567891011121314151617181920#1-1. 그룹별 갯수 확인tr_group = train_csv.sort_values(by=&quot;Label&quot;, ascending=False).groupby(by=[&#x27;Label&#x27;])print(tr_group.size().sort_values(ascending=False))print()#1-2. label 갯수 확인#l_list = []la_map = &#123;&#125;for idx, label in enumerate(train_csv[&quot;Label&quot;]): for one_la in label.split(&quot;|&quot;): if one_la in la_map.keys(): la_map[one_la] = la_map[one_la] + 1 else: la_map[one_la] = 0for idx, label in enumerate(la_map.keys()): print(&#x27;idx:&#x27;, idx, &#x27;,label count:&#x27;, la_map[label])print()#1-3. uniq label 갯수 확인print(&#x27;uniq label:&#x27;, len(la_map.keys())) 코드 https://www.kaggle.com/unkukjeong/notebookd8ea319370","categories":[{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Competition","slug":"ai/competition","permalink":"https://jukyellow.github.io/categories/ai/competition/"}],"tags":[{"name":"Kaggle","slug":"kaggle","permalink":"https://jukyellow.github.io/tags/kaggle/"},{"name":"캐글","slug":"캐글","permalink":"https://jukyellow.github.io/tags/%EC%BA%90%EA%B8%80/"},{"name":"kaggle notebook","slug":"kaggle-notebook","permalink":"https://jukyellow.github.io/tags/kaggle-notebook/"},{"name":"competition","slug":"competition","permalink":"https://jukyellow.github.io/tags/competition/"}]},{"title":"Hexo-Category-2Depth-Display","slug":"hexo-category-2depth-display","date":"2021-03-13T13:58:05.000Z","updated":"2021-03-13T14:49:39.503Z","comments":true,"path":"2021/03/13/hexo-category-2depth-display/","link":"","permalink":"https://jukyellow.github.io/2021/03/13/hexo-category-2depth-display/","excerpt":"","text":"개요 내가 사용한 Hexo 테마(BeanTech)에는 카테고리 기능이 없었다. 이전 포스팅한 기능패치 포스트(https://jukyellow.github.io/2021/02/25/bug-patch-tuning/)에서 참고 페이지에서 힌트를 찾았고 그냥 날코딩(감으로) 삽질끝에 원하는 형태 구현 성공! Post 카테고리 작성법 아래와 같이 Post작성시 헤더에 Parent/Child 그룹으로 구성가능 Child가 없을때 Parent로만 구성됨 카테고리 페이지 화면설명 (2) 상단에는 선택한 Parent 노드 출력 (3) Child 노드중에서도 선택한 항목을 최상단에 출력 (4) 선택하지 않은 Parent는 하위에 차례로 출력 (5) 세모박스 클릭시 노드 닫아두기 가능(닫아둔채로 생성도 가능) 구현 가이드?ejs 문법(생략) Embedded JavaScript templates : 자바스트립트를 할 줄 알면 대충 읽을수 있음 선택된 카테고리 정보12&lt;% page.posts.each(post=&gt;&#123; %&gt; &lt;% p_category = post.categories; //선택된 카테고리 %&gt; 전체 카테고리 순회12345&lt;% site.categories.each(function(p_item)&#123; &lt;!-- 선택한 카테고리가 아니면 제외 --&gt; &lt;% if(p_category.data[0]._id != p_item._id || (p_category.data[1]!=undefined &amp;&amp; p_category.data[1].parent != p_item._id))&#123; %&gt; &lt;% return true; //continue %&gt; &lt;% &#125; %&gt; Parent가 존재하는 Child1&lt;% if(c_item.parent!=undefined &amp;&amp; p_item._id == c_item.parent)&#123; %&gt; 현재 선택한 Child 전체 출력 현재 선택한 카테고리(child) ID와 순회중인 child_id 비교(c_item._id == p_category.data[1]._id) 전체 포스트를 순회(&lt;% site.posts.sort(‘date’, -1).forEach(function(it){ %&gt;)하며 선택한 카테고리 id에 속하는 포스트 출력 1234567891011121314151617181920&lt;% site.posts.sort(&#x27;date&#x27;, -1).forEach(function(it)&#123; %&gt; &lt;% if (it.categories.length == 2 &amp;&amp; it.categories.data[1]._id == c_item._id &amp;&amp; c_item._id == p_category.data[1]._id)&#123; %&gt; &lt;% if (head_2d_cnt==0) &#123; %&gt; &lt;h4 style=&quot;margin:10px 0 10px;&quot; class=&quot;archive-ul show&quot; data-toggle=&quot;collapse&quot; id=&quot;&lt;%= c_item.name %&gt;&quot; data-target=&quot;#modal-&lt;%= c_item.name %&gt;&quot;&gt; &amp;nbsp;&amp;nbsp;&lt;%= c_item.name %&gt; &lt;b class=&quot;caret&quot;&gt;&lt;/b&gt;&lt;/h4&gt; &lt;ul style=&quot;margin-bottom: 10px;&quot; id=&quot;modal-&lt;%= c_item.name %&gt;&quot; class=&quot;collapse in&quot;&gt; &lt;% site.posts.sort(&#x27;date&#x27;, -1).forEach(function(it)&#123; %&gt; &lt;% if (it.categories.length == 2 &amp;&amp; it.categories.data[1]._id == c_item._id &amp;&amp; it.categories.data[1]._id == p_category.data[1]._id)&#123; %&gt; &lt;li class=&quot;listing-item&quot;&gt; &lt;%= it.date.format(&#x27;MM-DD&#x27;) %&gt; &lt;i class=&quot;fa fa-angle-double-right&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;a href=&quot;&lt;%= config.root %&gt;&lt;%= it.path %&gt;&quot; &lt;% if (it.description) &#123; %&gt; title=&quot;&lt;%= it.description %&gt;&quot; &lt;% &#125; %&gt;&gt;&lt;%= it.title %&gt;&lt;/a&gt; &lt;/li&gt; &lt;% &#125; %&gt; &lt;% &#125;); %&gt; &lt;/ul&gt; &lt;% ++head_2d_cnt; %&gt; &lt;% &#125; %&gt; &lt;% return false; //break %&gt; &lt;% &#125; %&gt;&lt;% &#125;); %&gt; child 닫은채 출력 현재 child가 열린채 출력 리스트의 하위 목록으로 id를 지정(data-target=”#modal-&lt;%= c_item.name %&gt;) 12&lt;h4 style=&quot;margin:10px 0 10px;&quot; class=&quot;archive-ul show&quot; data-toggle=&quot;collapse&quot; id=&quot;&lt;%= c_item.name %&gt;&quot; data-target=&quot;#modal-&lt;%= c_item.name %&gt;&quot;&gt; &amp;nbsp;&amp;nbsp;&lt;%= c_item.name %&gt; &lt;b class=&quot;caret&quot;&gt;&lt;/b&gt;&lt;/h4&gt;&lt;ul style=&quot;margin-bottom: 10px;&quot; id=&quot;modal-&lt;%= c_item.name %&gt;&quot; class=&quot;collapse in&quot;&gt; child를 닫은채로 출력 하위 tag에서 class값을 “collapse”로 설정 12&lt;h4 style=&quot;margin:10px 0 10px;&quot; class=&quot;archive-ul show&quot; data-toggle=&quot;collapse&quot; id=&quot;&lt;%= c_item.name %&gt;&quot; data-target=&quot;#modal-&lt;%= c_item.name %&gt;&quot;&gt; &amp;nbsp;&amp;nbsp;&lt;%= c_item.name %&gt; &lt;b class=&quot;caret&quot;&gt;&lt;/b&gt;&lt;/h4&gt;&lt;ul style=&quot;margin-bottom: 10px;&quot; id=&quot;modal-&lt;%= c_item.name %&gt;&quot; class=&quot;collapse&quot;&gt; Source 적용버전: https://github.com/jukyellow/hexo-blog/blob/main/themes/beantech/layout/category.ejs 주석버전: https://github.com/jukyellow/hexo-blog/blob/main/themes/beantech/layout/category_comment.ejs","categories":[{"name":"Blog, PT","slug":"blog-pt","permalink":"https://jukyellow.github.io/categories/blog-pt/"},{"name":"Hexo","slug":"blog-pt/hexo","permalink":"https://jukyellow.github.io/categories/blog-pt/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://jukyellow.github.io/tags/hexo/"},{"name":"category.ejs","slug":"category-ejs","permalink":"https://jukyellow.github.io/tags/category-ejs/"},{"name":"hexo category","slug":"hexo-category","permalink":"https://jukyellow.github.io/tags/hexo-category/"},{"name":"category group","slug":"category-group","permalink":"https://jukyellow.github.io/tags/category-group/"}]},{"title":"Stock-Predict-by-CNN-CandleChart","slug":"stock-predict-by-cnn-candlechart","date":"2021-03-09T22:07:14.000Z","updated":"2021-03-14T00:32:18.794Z","comments":true,"path":"2021/03/10/stock-predict-by-cnn-candlechart/","link":"","permalink":"https://jukyellow.github.io/2021/03/10/stock-predict-by-cnn-candlechart/","excerpt":"","text":"머신러닝 및 딥러닝을 활용해 주식Data를 학습/예측하는 CNN 모델을 구현해보자 정확하게는 기업별 종가의 상승/하락 예측 참고도서: 퀀트 전략을 위한 인공지능 트레이닝 작업설명: 참고도서의 Python 버전을 Juputer nootebook버전으로 변경 작업순서1234561.야후주식-&gt;데이터 다운로드-&gt;CSV저장2.CSV-&gt;데이터별 라벨링3.CSV-&gt;업다운(1,0)-&gt;이미지(캔들) 저장4.이미지 라벨별 -&gt; 폴더이동, 학습전 data 복제5.모델학습 6.성능 테스트 주식 데이터 다운로드회사별 주식코드 조회123456code_df = pd.read_html(&#x27;http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&#x27;, header=0)[0]code_df = code_df[[&#x27;회사명&#x27;, &#x27;종목코드&#x27;]]code_df = code_df.rename(columns=&#123;&#x27;회사명&#x27;: &#x27;name&#x27;, &#x27;종목코드&#x27;: &#x27;code&#x27;&#125;)# 종목코드는 6자리로 구분되기때문에 0을 채워 6자리로 변경code_df.code = code_df.code.map(&#x27;&#123;:06d&#125;&#x27;.format)print(code_df.head()) 기업코드 조회 및 주식데이터 조회123456789101112131415161718# 참고: https://wendys.tistory.com/174# 회사명으로 주식 종목 코드를 획득할 수 있도록 하는 함수def get_code(df, name): code = df.query(&quot;name==&#x27;&#123;&#125;&#x27;&quot;.format(name))[&#x27;code&#x27;].to_string(index=False) # 위와같이 code명을 가져오면 앞에 공백이 붙어있는 상황이 발생하여 앞뒤로 sript() 하여 공백 제거 code = code.strip() return code# ex) 삼성전자의의 코드를 구해보겠습니다.code = get_code(code_df, &#x27;삼성전자&#x27;)# yahoo의 주식 데이터 종목은 코스피는 .KS, 코스닥은 .KQ가 붙습니다.# 삼성전자의 경우 코스피에 상장되어있기때문에 &#x27;종목코드.KS&#x27;로 처리하도록 한다.code = code + &#x27;.KS&#x27;print(&#x27;code:&#x27;, code)# get_data_yahoo API를 통해서 yahho finance의 주식 종목 데이터를 가져온다.df = pdr.get_data_yahoo(code)print(df.head()) 데이터 별 라벨링(Up-1, Down-0)주식 데이터 CSV 다운로드1234567891011121314151617181920def fetch_yahoo_data(ticker, start_date, end_date, fname, max_attempt, check_exist): if (os.path.exists(fname) == True) and check_exist: print(&quot;file exist&quot;) else: # remove exist file if os.path.exists(fname): os.remove(fname) for attempt in range(max_attempt): time.sleep(2) try: dat = data.get_data_yahoo(&#x27;&#x27;.join(&quot;&#123;&#125;&quot;.format( ticker)), start=start_date, end=end_date) dat.to_csv(fname) except Exception as e: if attempt &lt; max_attempt - 1: print(&#x27;Attempt &#123;&#125;: &#123;&#125;&#x27;.format(attempt + 1, str(e))) else: raise else: break 라벨링 상승세: 1, 하락세:0 으로 하루데이터별 txt파일 저장 1234567891011121314151617181920for i in range(0, len(df)): c = df.iloc[i:i + int(seq_len), :] starting = 0 endvalue = 0 label = &quot;&quot; if len(c) == int(seq_len): # starting = c[&quot;Close&quot;].iloc[-2] starting = c[&quot;Open&quot;].iloc[-1] endvalue = c[&quot;Close&quot;].iloc[-1] # print(f&#x27;endvalue &#123;endvalue&#125; - starting &#123;starting&#125;&#x27;) tmp_rtn = endvalue / starting -1 if tmp_rtn &gt; 0: label = 1 else: label = 0 with open(&quot;&#123;&#125;_label_&#123;&#125;.txt&quot;.format(filename[3][:-4], seq_len), &#x27;a&#x27;) as the_file: the_file.write(&quot;&#123;&#125;-&#123;&#125;,&#123;&#125;&quot;.format(filename[3][:-4], i, label)) the_file.write(&quot;\\n&quot;) 이미지 Candle chart 저장 주식지표를 이미지로 그리는 라이브러리 사용(candlestick2_ochl) https://github.com/matplotlib/mpl-finance -&gt; (변경됨) https://github.com/matplotlib/mplfinance 1234567891011121314151617181920212223242526272829303132333435363738394041for i in range(0, len(df)-int(seq_len)): # ohlc+volume c = df.iloc[i:i + int(seq_len), :] if len(c) == int(seq_len): my_dpi = 96 fig = plt.figure(figsize=(dimension / my_dpi, dimension / my_dpi), dpi=my_dpi) ax1 = fig.add_subplot(1, 1, 1) candlestick2_ochl(ax1, c[&#x27;Open&#x27;], c[&#x27;Close&#x27;], c[&#x27;High&#x27;],c[&#x27;Low&#x27;], width=1,colorup=&#x27;#77d879&#x27;, colordown=&#x27;#db3f3f&#x27;) ax1.grid(False) ax1.set_xticklabels([]) ax1.set_yticklabels([]) ax1.xaxis.set_visible(False) ax1.yaxis.set_visible(False) ax1.axis(&#x27;off&#x27;) # create the second axis for the volume bar-plot # Add a seconds axis for the volume overlay if use_volume: ax2 = ax1.twinx() # Plot the volume overlay bc = volume_overlay(ax2, c[&#x27;Open&#x27;], c[&#x27;Close&#x27;], c[&#x27;Volume&#x27;], colorup=&#x27;#77d879&#x27;, colordown=&#x27;#db3f3f&#x27;, alpha=0.5, width=1) ax2.add_collection(bc) ax2.grid(False) ax2.set_xticklabels([]) ax2.set_yticklabels([]) ax2.xaxis.set_visible(False) ax2.yaxis.set_visible(False) ax2.axis(&#x27;off&#x27;) pngfile = &#x27;dataset/&#123;&#125;_&#123;&#125;/&#123;&#125;/&#123;&#125;/&#123;&#125;-&#123;&#125;.png&#x27;.format( seq_len, dimension, symbol, dataset_type, symbol+&quot;_&quot;+dataset_type, i) fig.savefig(pngfile, pad_inches=0, transparent=False) plt.close(fig) # Alpha 채널 없애기 위한. from PIL import Image img = Image.open(pngfile) img = img.convert(&#x27;RGB&#x27;) img.save(pngfile) 이미지 라벨별 폴더이동데이터별 폴더 이동 학습할 이미지를 1, 0 폴더로 이동 소스1(주식 데이터 다운로드 생성) https://github.com/jukyellow/machine-learning-finance/blob/main/00_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%94%A9/02_%EC%95%8C%EA%B3%A0%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%94%A9/08_1_1_CNN_Candle_Chart_Pred_ImgGen_20210309.ipynb CNN 모델설계 CNN(conv2d) 모델 설계 이미지 데이터에서 label(상승-1, 하락-1)을 예측하는 softmax 모델 구현해보자 def build_model(SHAPE, nb_classes, bn_axis, seed=None): input_layer = Input(shape=SHAPE) # (2021/03/10,juk) init -&gt; kernel_initializer, border_mode -&gt; padding # Step 1 x = Conv2D(32, 3, 3, kernel_initializer =&#39;glorot_uniform&#39;, padding=&#39;same&#39;, activation=&#39;relu&#39;)(input_layer) # Step 2 - Pooling x = MaxPooling2D(pool_size=(2, 2), padding=&#39;same&#39;)(x) # (2021/03/10,juk) add padding=&#39;same&#39; # Step 1 x = Conv2D(48, 3, 3, kernel_initializer =&#39;glorot_uniform&#39;, padding=&#39;same&#39;,activation=&#39;relu&#39;)(x) # Step 2 - Pooling x = MaxPooling2D(pool_size=(2, 2), padding=&#39;same&#39;)(x) x = Dropout(0.25)(x) # Step 1 x = Conv2D(64, 3, 3, kernel_initializer =&#39;glorot_uniform&#39;, padding=&#39;same&#39;, activation=&#39;relu&#39;)(x) # Step 2 - Pooling x = MaxPooling2D(pool_size=(2, 2), padding=&#39;same&#39;)(x) # Step 1 x = Conv2D(96, 3, 3, kernel_initializer =&#39;glorot_uniform&#39;, padding=&#39;same&#39;, activation=&#39;relu&#39;)(x) # Step 2 - Pooling x = MaxPooling2D(pool_size=(2, 2), padding=&#39;same&#39;)(x) x = Dropout(0.25)(x) # Step 3 - Flattening x = Flatten()(x) # Step 4 - Full connection x = Dense(256, activation=&#39;relu&#39;)(x) # (2021/03/10,juk) output_dim=256 -&gt; 256 # Dropout #x = Dropout(0.5)(x) x = Dense(2, activation=&#39;softmax&#39;)(x) model = Model(input_layer, x) model.summary() return model 성능평가 주식데이터의 예측 성능은 50% 전후를 넘지 않는다고 한다.(아직 납득하지 못함;;) 상승/하락을 예측하기 위해선 여러가지 변수(재무재표,경제지표 등등)가 상식적으로 필요하겠지만, 여기서는 주가데이터(candle chart:open/close 등)만으로 학습하였고, 이에대한 결과이다. 소스2(학습/예측/성능평가) https://github.com/jukyellow/machine-learning-finance/blob/main/00_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%94%A9/02_%EC%95%8C%EA%B3%A0%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%94%A9/08_1_2_CNN_Candle_Chart_Pred_Model_Training_20210309.ipynb 총평 주가데이터 및 Candle-Chart로 기업 주식의 상승/하락을 예측하는 딥러닝 모델을 구현해 봤다. 주가 데이터를 이미지로 활용/전처리하는 방법을 catch하게이는 충분한 예제인거 같다.","categories":[{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Finance","slug":"ai/finance","permalink":"https://jukyellow.github.io/categories/ai/finance/"}],"tags":[{"name":"주식예측","slug":"주식예측","permalink":"https://jukyellow.github.io/tags/%EC%A3%BC%EC%8B%9D%EC%98%88%EC%B8%A1/"},{"name":"CNN","slug":"cnn","permalink":"https://jukyellow.github.io/tags/cnn/"},{"name":"Candle Chart","slug":"candle-chart","permalink":"https://jukyellow.github.io/tags/candle-chart/"},{"name":"Keras","slug":"keras","permalink":"https://jukyellow.github.io/tags/keras/"},{"name":"Conv2D","slug":"conv2d","permalink":"https://jukyellow.github.io/tags/conv2d/"},{"name":"Stock","slug":"stock","permalink":"https://jukyellow.github.io/tags/stock/"}]},{"title":"Linux-Command","slug":"linux-command","date":"2021-03-04T21:36:43.000Z","updated":"2021-04-01T21:26:40.736Z","comments":true,"path":"2021/03/05/linux-command/","link":"","permalink":"https://jukyellow.github.io/2021/03/05/linux-command/","excerpt":"","text":"유닉스(솔라리스) OS에서 Java 데몬 서비스를 운영하면서, 주로 사용했던 명령어들을 정리하였다. 리눅스 명령어OS버전 확인솔라리스1234- 커널 버전확인$ uname -a - 패키지버전 확인$ cat /etc/relese 우분투1234- 커널 버전확인$ uname -a- 패키지버전 확인$ cat /etc/issue CentOS12- 패키지 버전확인$ cat /etc/system-release. 프로세스 목록12- 특정프로세스 확인ps -ef | grep 문자열 조회 명령어12345678- 최신 변경 파일순 상세 조회$ ls -alrt- 하위 디렉토리까지 파일수 세기$ ls -lR | wc -l - 파일내 data 조회$ grep -l &quot;문자열&quot; * // 모든 파일에서 검색, *제일 많이 씀$ grep 문자열 파일명 // 특정 파일에서 문자열이 포함된 라인출력$ grep -c 문자열 파일명 // 특정 파일에서 문자열이 포함된 라인의 갯수 출력 IP/PORT 체크123456- Listen(점유) port 확인$ netstat -an | grep 8040- 방화벽 오픈여부 확인$ telnet ip port- 도메인의 IP 주소 확인$ nslookup 도메인명 스토리지 용량체크123456789101112- 디스크 잔여 용량(disk free)$ df -h // 사용자가 보기 쉬운 단위로&#123;KB, MB, GB&#125; 잔여량 표시, *제일 많이 씀$ df . // 현재 디렉토리가 포함된 파티션의 남은 공간을 보여준다.$ df -k // Kilobyte 단위로 현재 마운트된 파티션들의 남은 공간을 보여준다.$ df -F ufs -o i // inode 파일갯수 확인(100%차면 파일쓰기등 안됨)-디스크 현재 사용량(disk Usage)$ du -sh * // 현재 디렉토리 사용용량(하위폴더 포함), *제일 많이 씀$ du -h // 현재 디렉토리의 사용용량(사용자가 보기쉬운값으로)$ du -k // Kilobyte 사용용량 표시$ du -s * | awk &#x27;$1 &gt; 100000&#x27; // 특정용량 이상조회!&gt; 참고: https://ko.wikipedia.org/wiki/Du_(%EC%9C%A0%EB%8B%89%EC%8A%A4) 압축/해제123456789- 파일 압축$ tar -cvf 파일이름 압축할파일 혹은 /디렉토리- 파일 해제(압축풀기)$ tar -xvf 파일이름- jar 파일 리스트 보기$ jar -tvf jar파일명- jar 파일 압축 풀기$ jar -xvf jar파일명 Session 관리1234- 세션 타임아웃 변경echo $TMOUTexport TMOUT=18000 # 5시간echo $TMOUT 리눅스 변천사 사용버전은 크게 솔라리스와 레드헷, 개발자들은 우분투를 많이 씀 12345678 유닉스(커널) SunOS(커널) 솔라리스(배포판, 상용) 리눅스(커널) 리눅스(무료) 레드헷 (상용)우분투(무료) 페도라 센토스(무료) 이미지 출처: https://upload.wikimedia.org/wikipedia/commons/b/bc/Unix-like_history.svg","categories":[{"name":"Linux","slug":"linux","permalink":"https://jukyellow.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://jukyellow.github.io/tags/linux/"},{"name":"unix","slug":"unix","permalink":"https://jukyellow.github.io/tags/unix/"},{"name":"centos","slug":"centos","permalink":"https://jukyellow.github.io/tags/centos/"},{"name":"명령어","slug":"명령어","permalink":"https://jukyellow.github.io/tags/%EB%AA%85%EB%A0%B9%EC%96%B4/"},{"name":"OS버전","slug":"os버전","permalink":"https://jukyellow.github.io/tags/os%EB%B2%84%EC%A0%84/"}]},{"title":"Hexo Bug Patch and Tuning","slug":"bug-patch-tuning","date":"2021-02-24T22:05:40.000Z","updated":"2021-03-16T21:24:01.524Z","comments":true,"path":"2021/02/25/bug-patch-tuning/","link":"","permalink":"https://jukyellow.github.io/2021/02/25/bug-patch-tuning/","excerpt":"","text":"개요 Hexo가 blog 설치/구동에 편하긴한데, 테마를 품질에 따라 튜닝요소가 많이 필요한듯 하다. beantech 테마를 사용중인데, 여기저기 문제가 많아서 소소히 고쳐가며 쓰고 있다. 발견된 문제점들(미해결 사항) google analytics 연동오류 : google의 애널리스틱 -&gt; 데이터 스트림방식으로 설정이 바뀐것에 대한 수정작업 필요한듯 (2021.03.17) 검색엔진 최적화(SEO) 관련 플러그인 설치/설정후 정상적으로 동작함을 확인 방문자 count 문제 : tistory처럼 쉽게 설정할수 없음. 방문자 count 서비스를 찾아서 붙여야하는데, 잘 정리된 레퍼런스를 찾을수 없음 Total/today/yesterday 형태가 가장 보기 좋음 SNS settings에 medium 연결기능은 없음 : 이것도 기존꺼 참고해서 코딩가능한 부분인가? Blog 설정들 댓글기능 추가: Disqus(https://disqus.com/) 가입 및 Hexo 설정(_config.yml)12# Disqus settingsdisqus_username: yelran-s-tech-blog #jukyellow.github.io 방문자 count 추가: github hits로 갈음 구글 검색엔진 노출 설정: sitemap.xml 추가, robots.txt 추가 등(참고 : https://ivelee.github.io/github/how-to-expose-github-blog-google-search/) 해결된이슈 + 추가기능 (bug) deploy 0 byte (bug) side-bar widgets (기능추가) achive 배경화면 (기능추가) category 페이지 (기능추가) 썸네일 (기능추가) 방문자 count deploy 0 byte 문제: hexo beantech 테마 적용후, deploy 단계에서 파일 0 bytes 오류 발생 해결: hexo 3.9버전이 버전이여서 문제인가 싶어, hexo init으로 새 폴더 생성(hexo 5.3.0버전)+ theme 복제 side-bar widgets 문제: side-bar widgets 목록 설정불가 해결: forEach문 오류발생(sidebar widgets 목록을 찾을수 없음) theme/beantech/_config.yml에 widgets목록을 직접 기입해서 해결됨, deploy도 성공 achive 배경화면 문제: achive, category 페이지 배경화면 누락 해결: theme/beantech/layout/_partial/header.ejs 파일 수정 (is_category, is_archive 추가) 123456789101112header.intro-header&#123; &lt;% if (is_home() || is_category() || is_archive() ) &#123; %&gt; background-image: url(&#x27;&lt;%= config.root + config[&quot;header-img&quot;] %&gt;&#x27;) /*config*/ &lt;%&#125; else if (is_post())&#123;%&gt; background-image: url(&#x27;&lt;%= page[&quot;header-img&quot;] %&gt;&#x27;) /*post*/ &lt;%&#125; else &#123;%&gt; background-image: url(&#x27;&lt;%= config.root + page[&quot;header-img&quot;] %&gt;&#x27;) /*page*/ &lt;%&#125; %&gt;&#125; category 페이지 문제: category 이슈 페이지에 achive 목록으로 나오는 현상 해결: theme/beantech/layout/category.ejs 추가(archive.ejs 복사) category.ejs 수정(category 단위의 목록 출력 + 선택한 category는 최상위에 출력 코딩) 참고: https://github.com/wzpan/hexo-theme-freemind/blob/master/layout/categories.ejs 설명: page의 카테고리 id와 site 전체의 카테고리 정보를 비교해서 처리 p_category.data[0]._id == item._id source: https://github.com/jukyellow/hexo-blog/blob/main/themes/beantech/layout/category.ejs 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;% if (site.categories.length) &#123; %&gt;&lt;div class=&quot;archive&quot;&gt; &lt;% var p_category = null; page.posts.each(post=&gt;&#123; p_category = post.categories; &#125;) %&gt; &lt;% site.categories.sort(&#x27;name&#x27;).each(function(item)&#123; %&gt; &lt;% if(p_category.data[0]._id == item._id)&#123; %&gt; &lt;h4 class=&quot;archive-ul show&quot; data-toggle=&quot;collapse&quot; id=&quot;&lt;%= item.name %&gt;&quot; data-target=&quot;#modal-&lt;%= item.name %&gt;&quot;&gt; &lt;%= item.name %&gt; &lt;b class=&quot;caret&quot;&gt;&lt;/b&gt;&lt;/h4&gt; &lt;% &#125; %&gt; &lt;ul id=&quot;modal-&lt;%= item.name %&gt;&quot; class=&quot;collapse in&quot;&gt; &lt;% site.posts.sort(&#x27;date&#x27;, -1).forEach(function(it)&#123; %&gt; &lt;% if (it.categories.length == 1 &amp;&amp; it.categories.data[0]._id == item._id &amp;&amp; p_category.data[0]._id == item._id)&#123; %&gt; &lt;li class=&quot;listing-item&quot;&gt; &lt;%= it.date.format(&#x27;MM-DD&#x27;) %&gt; &lt;i class=&quot;fa fa-angle-double-right&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;a href=&quot;&lt;%= config.root %&gt;&lt;%= it.path %&gt;&quot; &lt;% if (it.description) &#123; %&gt; title=&quot;&lt;%= it.description %&gt;&quot; &lt;% &#125; %&gt;&gt;&lt;%= it.title %&gt;&lt;/a&gt; &lt;/li&gt; &lt;% &#125; %&gt; &lt;% &#125;); %&gt; &lt;/ul&gt; &lt;% &#125;); %&gt; &lt;hr align=&quot;left&quot; style=&quot;border: solid 1px gray; width: 55%;&quot;&gt; &lt;% site.categories.sort(&#x27;name&#x27;).each(function(item)&#123; %&gt; &lt;% if(p_category.data[0]._id != item._id)&#123; %&gt; &lt;h4 class=&quot;archive-ul show&quot; data-toggle=&quot;collapse&quot; id=&quot;&lt;%= item.name %&gt;&quot; data-target=&quot;#modal-&lt;%= item.name %&gt;&quot;&gt; &lt;%= item.name %&gt; &lt;b class=&quot;caret&quot;&gt;&lt;/b&gt;&lt;/h4&gt; &lt;% &#125; %&gt; &lt;ul id=&quot;modal-&lt;%= item.name %&gt;&quot; class=&quot;collapse in&quot;&gt; &lt;% site.posts.sort(&#x27;date&#x27;, -1).forEach(function(it)&#123; %&gt; &lt;% if (it.categories.length == 1 &amp;&amp; it.categories.data[0]._id == item._id &amp;&amp; p_category.data[0]._id != item._id)&#123; %&gt; &lt;li class=&quot;listing-item&quot;&gt; &lt;%= it.date.format(&#x27;MM-DD&#x27;) %&gt; &lt;i class=&quot;fa fa-angle-double-right&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;a href=&quot;&lt;%= config.root %&gt;&lt;%= it.path %&gt;&quot; &lt;% if (it.description) &#123; %&gt; title=&quot;&lt;%= it.description %&gt;&quot; &lt;% &#125; %&gt;&gt;&lt;%= it.title %&gt;&lt;/a&gt; &lt;/li&gt; &lt;% &#125; %&gt; &lt;% &#125;); %&gt; &lt;/ul&gt; &lt;% &#125;); %&gt; &lt;/ul&gt;&lt;/div&gt;&lt;% &#125; %&gt; 썸네일 설명 post 목록 썸네일 기능 추가 설치 : https://www.npmjs.com/package/hexo-featured-image _config.xml 체크사항: URL path 설정 썸네일 이미지 설정: 개별 post 페이지의 헤더에 ‘featured_image’ path 추가 1featured_image: ./images/01_init.png 캡쳐 post 목록(index.ejs) 튜닝 : 썸네일이 있을때는 div를 두개로(가로분할) 구성 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;% page.posts.each(function(post)&#123; %&gt; &lt;% if (!post.featured_image)&#123; %&gt; &lt;div class=&quot;post-preview&quot; style=&quot;float: left; width: 100%;&quot;&gt; &lt;a href=&quot;&lt;%- config.root %&gt;&lt;%- post.path %&gt;&quot;&gt; &lt;h2 class=&quot;post-title&quot;&gt; &lt;%- post.title || &quot;Untitled&quot; %&gt; &lt;/h2&gt; &lt;h3 class=&quot;post-subtitle&quot;&gt; &lt;%- post.subtitle || &quot;&quot; %&gt; &lt;/h3&gt; &lt;div class=&quot;post-content-preview&quot;&gt; &lt;%- truncate(strip_html(post.content), &#123;length: 140, omission: &#x27;...&#x27;&#125;) %&gt;... &lt;/div&gt; &lt;/a&gt; &lt;% if (config.home_posts_tag)&#123;%&gt; &lt;p class=&quot;post-meta&quot; style=&quot;margin: 10px 0;&quot;&gt; Posted by &lt;%- post.author || config.author %&gt; on &lt;%= post.date.format(config.date_format) %&gt; &lt;/p&gt; &lt;div class=&quot;tags&quot;&gt; &lt;% post.tags.forEach(function(tag)&#123; %&gt; &lt;a href=&quot;&lt;%= config.root %&gt;tags/#&lt;%= tag.name %&gt;&quot; title=&quot;&lt;%= tag.name %&gt;&quot;&gt;&lt;%= tag.name %&gt;&lt;/a&gt; &lt;% &#125;) %&gt; &lt;/div&gt; &lt;%&#125; else &#123;%&gt; &lt;p class=&quot;post-meta&quot;&gt; Posted by &lt;%- post.author || config.author %&gt; on &lt;%= post.date.format(config.date_format) %&gt; &lt;/p&gt; &lt;%&#125;%&gt; &lt;/div&gt; &lt;% &#125;else&#123; %&gt; &lt;div class=&quot;post-preview&quot; style=&quot;float: left; width: 70%; padding:5px;&quot;&gt; &lt;a href=&quot;&lt;%- config.root %&gt;&lt;%- post.path %&gt;&quot;&gt; &lt;h2 class=&quot;post-title&quot;&gt; &lt;%- post.title || &quot;Untitled&quot; %&gt; &lt;/h2&gt; &lt;h3 class=&quot;post-subtitle&quot;&gt; &lt;%- post.subtitle || &quot;&quot; %&gt; &lt;/h3&gt; &lt;div class=&quot;post-content-preview&quot;&gt; &lt;!-- &lt;%- truncate(strip_html(post.content), &#123;length: 100, omission: &#x27;...&#x27;&#125;) %&gt; --&gt; &lt;%- truncate(strip_html(post.content), &#123;length: 85, omission: &#x27;...&#x27;&#125;) %&gt; &lt;/div&gt; &lt;/a&gt; &lt;% if (config.home_posts_tag)&#123;%&gt; &lt;p class=&quot;post-meta&quot; style=&quot;margin: 10px 0;&quot;&gt; Posted by &lt;%- post.author || config.author %&gt; on &lt;%= post.date.format(config.date_format) %&gt; &lt;/p&gt; &lt;div class=&quot;tags&quot;&gt; &lt;% post.tags.forEach(function(tag)&#123; %&gt; &lt;a href=&quot;&lt;%= config.root %&gt;tags/#&lt;%= tag.name %&gt;&quot; title=&quot;&lt;%= tag.name %&gt;&quot;&gt;&lt;%= tag.name %&gt;&lt;/a&gt; &lt;% &#125;) %&gt; &lt;/div&gt; &lt;%&#125; else &#123;%&gt; &lt;p class=&quot;post-meta&quot;&gt; Posted by &lt;%- post.author || config.author %&gt; on &lt;%= post.date.format(config.date_format) %&gt; &lt;/p&gt; &lt;%&#125;%&gt; &lt;/div&gt; &lt;div class=&quot;post-preview&quot; style=&quot;float: left; width: 30%; padding:5px;&quot;&gt; &lt;% if (post.featured_image)&#123; %&gt; &lt;img src=&quot;&lt;%- post.featured_image %&gt;&quot;&gt; &lt;% &#125; %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;hr&gt;&lt;% &#125;); %&gt; 방문자 count busuanzi_container : sidebar.ejs 123456&lt;span id=&quot;busuanzi_container_site_pv&quot;&gt; [ 조회수:&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;busuanzi_container_site_uv&quot;&gt; | 방문자수:&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt; ]&lt;/span&gt; github hits : footer.ejs 123&lt;a href=&quot;http://hits.dwyl.com/&#123;&#123; site.url | remove_first: &#x27;https://&#x27; | remove_first: &#x27;http://&#x27; &#125;&#125;&#123;&#123; page.url &#125;&#125;&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;http://hits.dwyl.com/&#123;&#123; site.url | remove_first: &#x27;https://&#x27; | remove_first: &#x27;http://&#x27; &#125;&#125;&#123;&#123; page.url &#125;&#125;.svg&quot; /&gt;&lt;/a&gt;","categories":[{"name":"Blog, PT","slug":"blog-pt","permalink":"https://jukyellow.github.io/categories/blog-pt/"},{"name":"Hexo","slug":"blog-pt/hexo","permalink":"https://jukyellow.github.io/categories/blog-pt/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://jukyellow.github.io/tags/hexo/"},{"name":"hexo bug patch","slug":"hexo-bug-patch","permalink":"https://jukyellow.github.io/tags/hexo-bug-patch/"},{"name":"category.ejs","slug":"category-ejs","permalink":"https://jukyellow.github.io/tags/category-ejs/"}]},{"title":"Docker-Install-Root-Dir-Modify","slug":"docker-install-root-dir-modify","date":"2021-02-22T20:30:53.000Z","updated":"2021-04-01T21:37:26.278Z","comments":true,"path":"2021/02/23/docker-install-root-dir-modify/","link":"","permalink":"https://jukyellow.github.io/2021/02/23/docker-install-root-dir-modify/","excerpt":"","text":"설치환경 OS: CentOS 7.2 Docker: Docker Comunity 20.0.3? Docker (재)설치 도커가 이미 설치된 경우, 관련 파일/패키지를 삭제하고 재설치를 수행해야 한다. 컨테이너 종료, 이미지 삭제123docker stop $(docker ps -q)docker rm $(docker ps -a -q)docker rmi $(docker images -q) 서비스 중지12systemctl stop docker.servicesystemctl stop containerd.service 설치된 패키지 확인/삭제1234yum list installed | grep dockeryum erase containerd.io.x86_6yum erase docker-ce.x86_64yum erase docker-ce-cli.x86_64 디렉토리/파일 삭제123rm -rf /var/lib/dockercd /var/runrm docker.sock docker.pid 도커 재설치/확인12yum install -y docker-ceyum list installed | grep docker 도커 enable/start12345systemctl enable docker.servicesystemctl enable containerd.servicesystemctl start docker.servicesystemctl status docker.serviceservice status docker 참고 http://cloudrain21.com/remove-docker-forcely-and-reinstall Root Dir 변경 Docker 설치를 Root 계정으로 하는경우, Docker image 저장경로가 /var/lib/docker에 잡힘에 따라 Root 공간을 점유하게 된다. Root 공간은 OS 영역이므로 스토리지 관리에 문제(공간부족 등)가 되고, 보통은 별도의 디스크를 마운트하여 할당하는 것이 좋다. 설치 경로 확인:12cd /var/lib/dockerls -F 현재 dir-root 확인123docker info | grep &quot;Docker Root Dir&quot;docker volume inspect my-volsystemctl status docker.service 스크립트 파일변경123vi /usr/lib/systemd/system/docker.service( - ExecStart로 시작하는 라인 끝에 --data-root=/docker/root/dir 추가)ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --data-root=/home/docker 데이터 복사/재시작 Docker Root 디렉토리의 데이타 복사 또는 이동 및 Docker 서비스 재시작 12345systemctl daemon-reload systemctl stop dockermkdir /home/docker2cp -rp /var/lib/docker /home/ =&gt; 파일 복사systemctl start docker Root 변경확인123docker info | grep &quot;Docker Root Dir&quot;(Docker Root Dir: /home/docker =&gt; 변경된 root dir )docker volume inspect my-vol 실행권한 추가 root권한으로 설치된경우, user권한에 실행권한 추가 참고: https://github.com/occidere/TIL/issues/116 1sudo chmod 666 /var/run/docker.sock 참고 https://fliedcat.tistory.com/113","categories":[{"name":"MSA","slug":"msa","permalink":"https://jukyellow.github.io/categories/msa/"},{"name":"Docker","slug":"msa/docker","permalink":"https://jukyellow.github.io/categories/msa/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jukyellow.github.io/tags/docker/"},{"name":"docker install","slug":"docker-install","permalink":"https://jukyellow.github.io/tags/docker-install/"},{"name":"Root Dir","slug":"root-dir","permalink":"https://jukyellow.github.io/tags/root-dir/"},{"name":"Centos","slug":"centos","permalink":"https://jukyellow.github.io/tags/centos/"},{"name":"MSA","slug":"msa","permalink":"https://jukyellow.github.io/tags/msa/"}]},{"title":"OCR-Tesseract-Demo","slug":"OCR-Tesseract-Demo","date":"2021-02-19T21:59:11.000Z","updated":"2021-03-23T20:49:21.385Z","comments":true,"path":"2021/02/20/OCR-Tesseract-Demo/","link":"","permalink":"https://jukyellow.github.io/2021/02/20/OCR-Tesseract-Demo/","excerpt":"","text":"현재 인터넷에 공개되 있는 ‘Tesseract 데모 페이지 구현 블로그’는 구 레파지토리(google) 버전이라 실행이 불가능하다. 하여 최신 레파지토리(github) 기준으로 동작가능한 데모 페이지로 오류를 수정하여 내용을 공개한다. 또한, 기존 블로그는 모바일 환경을 지원하지 않지만, 모바일에서 카메라 캡처-&gt;Text추출 가능한 소스로 업데이트 예정이다. 실행화면 초기화면 Text 추출 결과 tesseract 다운로드도커 이미지 다운로드 https://tesseract-ocr.github.io/ https://tesseract-ocr.github.io/tessdoc/ https://tesseract-ocr.github.io/tessdoc/4.0-Docker-Containers.html Tesseract 4 OCR Runtime Environment - Docker Container(레파지토리) https://github.com/tesseract-shadow/tesseract-ocr-re image 다운로드1docker pull tesseractshadow/tesseract4re . 샘플 테스트 (복사 &amp; 실행) test.sh 12docker cp ./ocr-files/phototest.tif t4re:/home/work/$TASK_TMP_DIR/docker exec -it t4re /bin/bash -c &quot;mkdir -p ./$TASK_TMP_DIR/out/; cd ./$TASK_TMP_DIR/out/; tesseract ../phototest.tif phototest -l eng --psm 1 --oem 3 txt pdf hocr&quot; 데모 페이지pytesseract 설치 및 Flask 웹서버 연동 출처: https://realpython.com/setting-up-a-simple-ocr-server/#web-server-time (source) https://github.com/ybur-yug/python_ocr_tutorial (tesseract 설치/구동까지는 1번참고, 해당 자료는 tesseract 구레파지토리를 사용하는 옛날버전인듯)pytesseract를 설치하는 부분은 1)번 + 별도 dockerfile로 구성 도커실행 5000: ocr tesseract flask port 12docker build -t ocr_tesseract_web .docker run --name ocr_tesseract_web --publish 5000:5000 -it ocr_tesseract_web dockerfile tesseractshadow/tesseract4re + Flask 웹서버 구동을 위해서 일부 오류수정 추가1234567891011121314151617181920212223242526# start with a base image# FROM ubuntu:14.04FROM tesseractshadow/tesseract4re## install dependenciesRUN apt-get updateRUN apt-get install -y liblog4cplus-devRUN apt-get install -y python python-pipRUN lsWORKDIR /RUN lsADD requirements.txt /RUN pip install -r requirements.txt# pil error : decoder jpeg not availableRUN pip uninstall Pillow -yRUN apt-get install -y libjpeg-devRUN pip install Pillow# update working directoriesADD ./flask_server /flask_serverWORKDIR /flask_server#EXPOSE 5000CMD [&quot;python&quot;, &quot;app.py&quot;] Flask app app.py 1234567891011121314151617181920212223242526@app.route(&#x27;/&#x27;)def main(): return render_template(&#x27;index.html&#x27;)@app.route(&#x27;/v&#123;&#125;/ocr&#x27;.format(_VERSION), methods=[&quot;POST&quot;])def ocr(): print(&#x27;--call ocr processing --&#x27;) try: if request.files.get(&quot;image&quot;): print(&#x27;--read image --&#x27;) # read the image in PIL format image = request.files[&quot;image&quot;].read() image = Image.open(io.BytesIO(image)) print(&#x27;RECV:&#x27;, image.format, image.size, image.mode) output = process_image2(image) print(&#x27;output:&#x27;, output) return jsonify(&#123;&quot;output&quot;: output&#125;) else: return jsonify(&#123;&quot;error&quot;: &quot;only .jpg files, please&quot;&#125;) except Exception as e: print(&#x27;ocr processing exception:&#x27; , e) print(traceback.format_exc()) return jsonify( &#123;&quot;error&quot;: str(e)&#125; ) javascript 123456789101112131415161718192021222324252627282930313233$(&#x27;#submit&#x27;).on(&#x27;click&#x27;, function(event)&#123; $(&quot;#results&quot;).hide() var data = new FormData(); if(is_mobile)&#123; var cFile = getCaptureImg(); data.append(&quot;image&quot;, cFile); &#125;else&#123; var file = $(&#x27;#file&#x27;)[0].files[0]; data.append(&quot;image&quot;, file); &#125; $.ajax(&#123; type: &quot;POST&quot;, url: &quot;/v1/ocr&quot;, enctype: &#x27;multipart/form-data&#x27;, data : data, processData: false, contentType: false, cache: false, timeout: 600000, success: function(result) &#123; console.log(result); $(&quot;#post-form&quot;).hide() $(&quot;#retry&quot;).show() $(&quot;#results&quot;).show() $(&quot;#results-data&quot;).html(&quot;&lt;div class=&#x27;well&#x27;&gt;&quot;+result[&quot;output&quot;]+&quot;&lt;/div&gt;&quot;); &#125;, error: function(error) &#123; console.log(error); &#125; &#125;);&#125;); Source 전체 source: https://github.com/jukyellow/artificial-intelligence-study/tree/master/13_ImageProcessing/OCR(Tesseract)/pytessract_dockerfike 참고: PC 크롬환경에서 테스트완료, 모바일 환경은 테스트 못함(소스는 모바일(아이폰) 환경도 가능한 모듈로 구성)","categories":[{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Image","slug":"ai/image","permalink":"https://jukyellow.github.io/categories/ai/image/"}],"tags":[{"name":"OCR","slug":"ocr","permalink":"https://jukyellow.github.io/tags/ocr/"},{"name":"Tesseract","slug":"tesseract","permalink":"https://jukyellow.github.io/tags/tesseract/"},{"name":"Docker","slug":"docker","permalink":"https://jukyellow.github.io/tags/docker/"},{"name":"Text추출","slug":"text추출","permalink":"https://jukyellow.github.io/tags/text%EC%B6%94%EC%B6%9C/"}]},{"title":"Face Check in 구현","slug":"Face-Check-In","date":"2021-02-19T03:42:22.000Z","updated":"2021-03-10T21:27:58.499Z","comments":true,"path":"2021/02/19/Face-Check-In/","link":"","permalink":"https://jukyellow.github.io/2021/02/19/Face-Check-In/","excerpt":"","text":"개요 안면인식 + 동작감지 = (비접촉) 출석체크 안면인식과 동작감지 기술을 이용하여 비 접촉 출석체크 시스템을 구현해보았다. 오픈소스의 대중화와 머신러닝 프레임워크의 발전, 그리고 AI 민주화시대를 앞당기는 기업들의 노력으로, 앞으로 이런 수준의 서비스들은 추가적인 연구없이 현재 공개되어 있는 기술들로 충분히 구현 가능하다. Teachable Machine(2.0) https://teachablemachine.withgoogle.com/ 일반인도 머신러닝 서비스를 만들수 있는 플랫폼을 제공(2019년/Google) 학습~배포(json/api) 관련 파생 서비스: 관상가양반(https://yourface.ga/) 단점: 세세한 튜닝(최적화) 불가능-&gt;안면인식 성능 낮음 안면인식 OpenSourceFaceApi Javascript 구현체(tensorflow.js + node.js) github : https://github.com/justadudewhohacks/face-api.js/ 다양한 기능(face-tracking, recognition…) 내장하고 있지만 속도가 느림 Facenet(2015년/Google) Facenet: Embedding(백만명 사진 학습&gt;특징 임베딩 벡터&gt;98~99%) 블로그: https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/ 논문: https://arxiv.org/abs/1503.03832 시스템 구성/파이프라인 시스템 구성 작업절차: 안면인식(keras)&gt;동작인식(Teach)&gt;두 모델 기능병합(HTML5,JS)&gt;배포(Docker/Flask) Face Model(안면인식)은 Google Colab환경에서 학습하였다. Facenet 모델의 Embedding 벡터와 지도학습 방법인 서포터벡터머신(SVC)을 사용하여 얼굴예측 모델을 구현하여, 구현체를 H5(Keras 모델), Pickle(Skit-Learn 모델) 파일 형태로 출력한다. Pose Model(동작감지)은 Google Teachable Machine을 사용하여 팔의 동작(O,X,캡쳐,대기)을 학습시키고, 모델을 Json형태로 출력하였다. 서버에 설치는 Docker(Container 가상화 기술)를 사용하여 환경을 구성하였다. Docker를 사용하면 OS환경(Windows/Linux등)과 상관없이 개발환경 그대로 배포환경으로 옮길 수 있다는 장점이 있다. 또한 필요한 Library를 시스템 설치 없이 다운로드후 구동방식으로 동작 시킬 수 있기 때문에 개발 생산성도 좋아진다. Docker를 빌드하기 위해서는 yml 파일이나 Dockerfile이 필요한데, 여기서는 Dockerfile을 사용하였고 Base 이미지로 Keras(Tensorflow)/Flask 이미지 서버를 구성한 뒤, ML(Machine Learning) 출력파일을 올려서 컨테이너를 구성하였다. 배포서버의 도메인이 Https(Nginx) 로 구성되어 있어서, 웹서버(Nginx) 뒤에 WAS서버 형태로 시스템을 붙여야 했다. Flask ML 서버를 port를 분리하여 구동 시키고 Nginx의 URI 라우팅(Location 설정)을 수정하여 구성하였다. Flask는 Python 웹 애플리케이션 서버 역할을 하면서 동시에 웹서버(html, js 배포) 역할을 할 수 있기때문에, Flask 서버에 Html/Javascript 소스도 배포하였다. 이렇게 해서 화면단의 요청을 ML서버가 직접 받도록 구성하여 CORS(Cross-Origin Resource Sharing) 및 Https/Http 혼용사용 문제도 해결하였다. 활용기술안면인식(FaceNet) 사진(150명) Agumentation &gt; Embedding(특징벡터) &gt; SVC(서포트벡터머신) &gt; 예측 Facenet 모델은 기존 사람의 얼굴 윤곽을 잡아서 학습시키는 랜드마크 방식과 다르게, 사람 얼굴의 특정정보를 Embedding이라는 기하학적 공간에 사상시켜 훈련한데에 있다. 유명인 백만명을 학습시켜 Anchor 본인과 같은 사람의 사진이면 Positive로 보고 유클리드 공간상의 거리를 좁히고, 다른 사람이면 Negative로 보고 거리를 멀게 하도록 학습시키는 방식으로 Embedding 벡터를 훈련시켰다. 이 모델의 Embedding벡터를 사람 얼굴 특징 벡터로 Pre-Training 벡터로 사용하여 새로운 얼굴들을 추가 학습시키는 방법으로 활용 가능하다. 학습 절차 머신러닝 학습을 위해서는 여러 장의 사진이 필요하기 때문에, 사진을 복제/변형하여 추가(20장)로 훈련 데이터를 확보한다. 이후 얼굴추출 Library를 이용하여 좌표에 해당하는 이미지를 Slice한다. 이후 오픈소스로 존재하는 Facenet Embedding 벡터를 통과시켜 얼굴 특징점을 수치화한 Vector를 추출한 뒤 본격적인 학습과정이 수행된다. 수치 데이터의 분포가 일정하게 정규화 한 뒤, 사람별로 Labeling 과정을 거치고 지도학습 모델중의 하나인 서포터벡터머신(SVC)으로 훈련시켰다.학습모델은 변경이 가능하고 딥러닝 모델을 사용하려면 사진 개수가 충분히 많아야 한다. 훈련Set 사진으로 학습시킨 뒤 테스트Set 사진으로 성능을 보면 99.8%로 거의 100%가깝게 나왔지만, 실제로 웹캠으로 시연을 해보면, 성능이 다소 떨어지는데 이는 사진이 현재 얼굴과 많이 다르거나, 웹캠의 해상도 조명등의 영향 때문인데 조명으로 인한 성능차이는 전처리 기능을 보강하여 추가 개선 가능하다. Embedding Feacture 추출소스(Facenet-&gt;predict)1234567def get_embedding(model, face_pixels): face_pixels = face_pixels.astype(&#x27;float32&#x27;) mean, std = face_pixels.mean(), face_pixels.std() face_pixels = (face_pixels - mean) / std samples = expand_dims(face_pixels, axis=0) yhat = model.predict(samples) # make prediction to get embedding return yhat[0] 동작감지(Teachable Machine) 구글 Teachable Machine은 이미지/사운드/동작 이 세가지 학습방식을 지원하고, 일반인도 충분히 머신러닝 훈련 및 배포까지 가능한 환경을 제공하는 플랫폼이다. 이를 이용하여 팔의 동작 (O,X,캡쳐-두팔,대기)을 학습시켰다. 해당 플랫폼을 활용하여 만든 서비스 사례 중 하나가 ‘관상가 양반’(https://yourface.ga/)이다.바야흐로 AI 민주화(democratization) 시대가 열리고 있다. 우리도 이제 발맞춰 민첩하게 대응하고 목표를 추진할 수 있는 인력양성이 필요한 시점인 것 같다. Docker(Flask Web/ML Server) docker base img: https://hub.docker.com/repository/docker/jukyellow/keras-flask-img base img 생성방법: https://github.com/jukyellow/artificial-intelligence-study/tree/master/11_Serving/keras-flask-img 레퍼런스 (Facenet + SVC 이미지 학습) https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/ (Facenet Pre-Train model) https://www.microsoft.com/en-us/research/project/ms-celeb-1m-challenge-recognizing-one-million-celebrities-real-world/ (Jquery MultiPart-Form Ajax) https://mkyong.com/jquery/jquery-ajax-submit-a-multipart-form/ (Google Teachable Machine) https://teachablemachine.withgoogle.com/","categories":[{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Image","slug":"ai/image","permalink":"https://jukyellow.github.io/categories/ai/image/"}],"tags":[{"name":"facenet","slug":"facenet","permalink":"https://jukyellow.github.io/tags/facenet/"},{"name":"google teachable machine","slug":"google-teachable-machine","permalink":"https://jukyellow.github.io/tags/google-teachable-machine/"},{"name":"face recognition","slug":"face-recognition","permalink":"https://jukyellow.github.io/tags/face-recognition/"},{"name":"docker","slug":"docker","permalink":"https://jukyellow.github.io/tags/docker/"}]},{"title":"Markdown 기반 Slide Show 'Marp' 사용법","slug":"marp-guide","date":"2021-01-31T00:45:44.000Z","updated":"2021-03-16T20:33:03.552Z","comments":true,"path":"2021/01/31/marp-guide/","link":"","permalink":"https://jukyellow.github.io/2021/01/31/marp-guide/","excerpt":"","text":"https://marp-slide-guide.netlify.app/","categories":[{"name":"Blog, PT","slug":"blog-pt","permalink":"https://jukyellow.github.io/categories/blog-pt/"},{"name":"Presentation","slug":"blog-pt/presentation","permalink":"https://jukyellow.github.io/categories/blog-pt/presentation/"}],"tags":[{"name":"marp","slug":"marp","permalink":"https://jukyellow.github.io/tags/marp/"},{"name":"markdown","slug":"markdown","permalink":"https://jukyellow.github.io/tags/markdown/"},{"name":"slide","slug":"slide","permalink":"https://jukyellow.github.io/tags/slide/"}]},{"title":"Hexo Blog 스킨 적용 및 Github 배포","slug":"hexo-install-guide-1","date":"2021-01-29T22:00:45.000Z","updated":"2021-04-28T22:46:58.396Z","comments":true,"path":"2021/01/30/hexo-install-guide-1/","link":"","permalink":"https://jukyellow.github.io/2021/01/30/hexo-install-guide-1/","excerpt":"","text":"1. git/npm windows 설치 git과 npm이 사전에 설치되어 있어야한다. 2. hexo (기본 가이드 한글로 번역됨) https://hexo.io/ko/docs/ 123npm install hexo-cli -g --savenpm install hexo-server --savenpm install hexo-deployer-git --save 3. 테마 repo clone 테마 원본: https://github.com/YenYuHsuan/hexo-theme-beantech 테마 튜닝: https://github.com/jukyellow/hexo-blog1git clone https://github.com/jukyellow/hexo-blog 4. 경로진입 cd hexo-beantech 5. node 패키지 설치1npm install 6. 실행 hexo serve localhost:4000 확인 7. category 기능 활성화: _config.yml &gt; widgets 부분 category 주석풀기 + post에 작성시 category 추가 8. 기초세팅 _config.yml 설정(https://github.com/YenYuHsuan/hexo-theme-beantech 따라하기) 9. post작성 및 배포1234hexo new post &quot;&lt;post name&gt;&quot; # you can change post to another layout if you wanthexo clean &amp;&amp; hexo generate # generate the static filehexo server # run hexo in local environmenthexo deploy # hexo will push the static files automatically into the specific branch(gh-pages) of your repo! 기존 git 서버주소가 세팅된 경우, git주소 변경 및 windows 자격증명 변경필요 참고1: ( git 주소변경) https://mingpd.github.io/2019/04/14/github-blog-with-hexo-3/#%EC%9E%91%EC%97%85%ED%8C%8C%EC%9D%BC-Git-%EC%84%A4%EC%A0%95 참고2: (자격증명 삭제) https://recoveryman.tistory.com/39212$ git init$ git remote set-url origin https://github.com/작업용/깃주소.git 10. 버그 패치 hexo beantech 테마 적용후, deploy 단계에서 파일 0 bytes 오류 발생 hexo 3.9버전이 버전이여서 문제인가 싶어, hexo init으로 새 폴더 생성(hexo 5.3.0버전)+ theme 복제 forEach문 오류발생(sidebar widgets 목록을 찾을수 없음) theme/beantech/_config.yml에 widgets목록을 직접 기입해서 해결됨, deploy도 성공 11. tag/category 입력123456tags:- Hexo- Blog# or tags: [&quot;A&quot;, &quot;B&quot;]catagories:- Hexo 12. 무료 이미지 다운로드 https://www.freepik.comhttps://pixabay.com/https://unsplash.com/","categories":[{"name":"Blog, PT","slug":"blog-pt","permalink":"https://jukyellow.github.io/categories/blog-pt/"},{"name":"Hexo","slug":"blog-pt/hexo","permalink":"https://jukyellow.github.io/categories/blog-pt/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://jukyellow.github.io/tags/hexo/"},{"name":"hexo blog","slug":"hexo-blog","permalink":"https://jukyellow.github.io/tags/hexo-blog/"},{"name":"hexo install","slug":"hexo-install","permalink":"https://jukyellow.github.io/tags/hexo-install/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-01-28T21:45:44.000Z","updated":"2021-02-25T23:27:11.521Z","comments":true,"path":"2021/01/29/hello-world/","link":"","permalink":"https://jukyellow.github.io/2021/01/29/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"Childcare","slug":"childcare","permalink":"https://jukyellow.github.io/categories/childcare/"},{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/categories/data-scientist/"},{"name":"Note","slug":"data-scientist/note","permalink":"https://jukyellow.github.io/categories/data-scientist/note/"},{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/categories/ai/"},{"name":"Finance","slug":"ai/finance","permalink":"https://jukyellow.github.io/categories/ai/finance/"},{"name":"Competition","slug":"ai/competition","permalink":"https://jukyellow.github.io/categories/ai/competition/"},{"name":"Practice","slug":"data-scientist/practice","permalink":"https://jukyellow.github.io/categories/data-scientist/practice/"},{"name":"MSA","slug":"msa","permalink":"https://jukyellow.github.io/categories/msa/"},{"name":"Docker","slug":"msa/docker","permalink":"https://jukyellow.github.io/categories/msa/docker/"},{"name":"Linux","slug":"linux","permalink":"https://jukyellow.github.io/categories/linux/"},{"name":"Note","slug":"ai/note","permalink":"https://jukyellow.github.io/categories/ai/note/"},{"name":"Blog, PT","slug":"blog-pt","permalink":"https://jukyellow.github.io/categories/blog-pt/"},{"name":"Hexo","slug":"blog-pt/hexo","permalink":"https://jukyellow.github.io/categories/blog-pt/hexo/"},{"name":"Image","slug":"ai/image","permalink":"https://jukyellow.github.io/categories/ai/image/"},{"name":"Presentation","slug":"blog-pt/presentation","permalink":"https://jukyellow.github.io/categories/blog-pt/presentation/"}],"tags":[{"name":"육아","slug":"육아","permalink":"https://jukyellow.github.io/tags/%EC%9C%A1%EC%95%84/"},{"name":"감정코치","slug":"감정코치","permalink":"https://jukyellow.github.io/tags/%EA%B0%90%EC%A0%95%EC%BD%94%EC%B9%98/"},{"name":"육아노트","slug":"육아노트","permalink":"https://jukyellow.github.io/tags/%EC%9C%A1%EC%95%84%EB%85%B8%ED%8A%B8/"},{"name":"시계열분석","slug":"시계열분석","permalink":"https://jukyellow.github.io/tags/%EC%8B%9C%EA%B3%84%EC%97%B4%EB%B6%84%EC%84%9D/"},{"name":"time series","slug":"time-series","permalink":"https://jukyellow.github.io/tags/time-series/"},{"name":"ARCH","slug":"arch","permalink":"https://jukyellow.github.io/tags/arch/"},{"name":"GARCH","slug":"garch","permalink":"https://jukyellow.github.io/tags/garch/"},{"name":"VAR","slug":"var","permalink":"https://jukyellow.github.io/tags/var/"},{"name":"상태공간모형","slug":"상태공간모형","permalink":"https://jukyellow.github.io/tags/%EC%83%81%ED%83%9C%EA%B3%B5%EA%B0%84%EB%AA%A8%ED%98%95/"},{"name":"Stock","slug":"stock","permalink":"https://jukyellow.github.io/tags/stock/"},{"name":"Indicatior","slug":"indicatior","permalink":"https://jukyellow.github.io/tags/indicatior/"},{"name":"볼린저밴드","slug":"볼린저밴드","permalink":"https://jukyellow.github.io/tags/%EB%B3%BC%EB%A6%B0%EC%A0%80%EB%B0%B4%EB%93%9C/"},{"name":"이동평균선","slug":"이동평균선","permalink":"https://jukyellow.github.io/tags/%EC%9D%B4%EB%8F%99%ED%8F%89%EA%B7%A0%EC%84%A0/"},{"name":"모멘텀","slug":"모멘텀","permalink":"https://jukyellow.github.io/tags/%EB%AA%A8%EB%A9%98%ED%85%80/"},{"name":"변동성","slug":"변동성","permalink":"https://jukyellow.github.io/tags/%EB%B3%80%EB%8F%99%EC%84%B1/"},{"name":"ARMA","slug":"arma","permalink":"https://jukyellow.github.io/tags/arma/"},{"name":"ARIMA","slug":"arima","permalink":"https://jukyellow.github.io/tags/arima/"},{"name":"비트코인","slug":"비트코인","permalink":"https://jukyellow.github.io/tags/%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8/"},{"name":"모의투자","slug":"모의투자","permalink":"https://jukyellow.github.io/tags/%EB%AA%A8%EC%9D%98%ED%88%AC%EC%9E%90/"},{"name":"시계열","slug":"시계열","permalink":"https://jukyellow.github.io/tags/%EC%8B%9C%EA%B3%84%EC%97%B4/"},{"name":"ACF","slug":"acf","permalink":"https://jukyellow.github.io/tags/acf/"},{"name":"PACF","slug":"pacf","permalink":"https://jukyellow.github.io/tags/pacf/"},{"name":"데이터 분석","slug":"데이터-분석","permalink":"https://jukyellow.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D/"},{"name":"파이썬","slug":"파이썬","permalink":"https://jukyellow.github.io/tags/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"},{"name":"Panadas","slug":"panadas","permalink":"https://jukyellow.github.io/tags/panadas/"},{"name":"DataFrame","slug":"dataframe","permalink":"https://jukyellow.github.io/tags/dataframe/"},{"name":"K-means","slug":"k-means","permalink":"https://jukyellow.github.io/tags/k-means/"},{"name":"Sklearn","slug":"sklearn","permalink":"https://jukyellow.github.io/tags/sklearn/"},{"name":"LinearRegression","slug":"linearregression","permalink":"https://jukyellow.github.io/tags/linearregression/"},{"name":"강의노트","slug":"강의노트","permalink":"https://jukyellow.github.io/tags/%EA%B0%95%EC%9D%98%EB%85%B8%ED%8A%B8/"},{"name":"docker","slug":"docker","permalink":"https://jukyellow.github.io/tags/docker/"},{"name":"docker install","slug":"docker-install","permalink":"https://jukyellow.github.io/tags/docker-install/"},{"name":"Root Dir","slug":"root-dir","permalink":"https://jukyellow.github.io/tags/root-dir/"},{"name":"Centos","slug":"centos","permalink":"https://jukyellow.github.io/tags/centos/"},{"name":"MSA","slug":"msa","permalink":"https://jukyellow.github.io/tags/msa/"},{"name":"nslookup","slug":"nslookup","permalink":"https://jukyellow.github.io/tags/nslookup/"},{"name":"telnet","slug":"telnet","permalink":"https://jukyellow.github.io/tags/telnet/"},{"name":"hostname","slug":"hostname","permalink":"https://jukyellow.github.io/tags/hostname/"},{"name":"tracert","slug":"tracert","permalink":"https://jukyellow.github.io/tags/tracert/"},{"name":"ssh접속","slug":"ssh접속","permalink":"https://jukyellow.github.io/tags/ssh%EC%A0%91%EC%86%8D/"},{"name":"파일생성시간 삭제","slug":"파일생성시간-삭제","permalink":"https://jukyellow.github.io/tags/%ED%8C%8C%EC%9D%BC%EC%83%9D%EC%84%B1%EC%8B%9C%EA%B0%84-%EC%82%AD%EC%A0%9C/"},{"name":"2>&1","slug":"2-1","permalink":"https://jukyellow.github.io/tags/2-1/"},{"name":"웹서버설정","slug":"웹서버설정","permalink":"https://jukyellow.github.io/tags/%EC%9B%B9%EC%84%9C%EB%B2%84%EC%84%A4%EC%A0%95/"},{"name":"AI","slug":"ai","permalink":"https://jukyellow.github.io/tags/ai/"},{"name":"Lecture","slug":"lecture","permalink":"https://jukyellow.github.io/tags/lecture/"},{"name":"Kaist","slug":"kaist","permalink":"https://jukyellow.github.io/tags/kaist/"},{"name":"note","slug":"note","permalink":"https://jukyellow.github.io/tags/note/"},{"name":"머신러닝","slug":"머신러닝","permalink":"https://jukyellow.github.io/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/"},{"name":"빅데이터","slug":"빅데이터","permalink":"https://jukyellow.github.io/tags/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/"},{"name":"Data Analysis","slug":"data-analysis","permalink":"https://jukyellow.github.io/tags/data-analysis/"},{"name":"Data Scientist","slug":"data-scientist","permalink":"https://jukyellow.github.io/tags/data-scientist/"},{"name":"K-MOOC","slug":"k-mooc","permalink":"https://jukyellow.github.io/tags/k-mooc/"},{"name":"Colaboratory","slug":"colaboratory","permalink":"https://jukyellow.github.io/tags/colaboratory/"},{"name":"google colab","slug":"google-colab","permalink":"https://jukyellow.github.io/tags/google-colab/"},{"name":"google drive","slug":"google-drive","permalink":"https://jukyellow.github.io/tags/google-drive/"},{"name":"Jupter notebook","slug":"jupter-notebook","permalink":"https://jukyellow.github.io/tags/jupter-notebook/"},{"name":"drive file download","slug":"drive-file-download","permalink":"https://jukyellow.github.io/tags/drive-file-download/"},{"name":"keras","slug":"keras","permalink":"https://jukyellow.github.io/tags/keras/"},{"name":"hexo","slug":"hexo","permalink":"https://jukyellow.github.io/tags/hexo/"},{"name":"search engine optimization","slug":"search-engine-optimization","permalink":"https://jukyellow.github.io/tags/search-engine-optimization/"},{"name":"SEO","slug":"seo","permalink":"https://jukyellow.github.io/tags/seo/"},{"name":"검색엔진노출","slug":"검색엔진노출","permalink":"https://jukyellow.github.io/tags/%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84%EB%85%B8%EC%B6%9C/"},{"name":"robots.txt","slug":"robots-txt","permalink":"https://jukyellow.github.io/tags/robots-txt/"},{"name":"sitemap.xml","slug":"sitemap-xml","permalink":"https://jukyellow.github.io/tags/sitemap-xml/"},{"name":"Kaggle","slug":"kaggle","permalink":"https://jukyellow.github.io/tags/kaggle/"},{"name":"캐글","slug":"캐글","permalink":"https://jukyellow.github.io/tags/%EC%BA%90%EA%B8%80/"},{"name":"kaggle notebook","slug":"kaggle-notebook","permalink":"https://jukyellow.github.io/tags/kaggle-notebook/"},{"name":"competition","slug":"competition","permalink":"https://jukyellow.github.io/tags/competition/"},{"name":"category.ejs","slug":"category-ejs","permalink":"https://jukyellow.github.io/tags/category-ejs/"},{"name":"hexo category","slug":"hexo-category","permalink":"https://jukyellow.github.io/tags/hexo-category/"},{"name":"category group","slug":"category-group","permalink":"https://jukyellow.github.io/tags/category-group/"},{"name":"주식예측","slug":"주식예측","permalink":"https://jukyellow.github.io/tags/%EC%A3%BC%EC%8B%9D%EC%98%88%EC%B8%A1/"},{"name":"CNN","slug":"cnn","permalink":"https://jukyellow.github.io/tags/cnn/"},{"name":"Candle Chart","slug":"candle-chart","permalink":"https://jukyellow.github.io/tags/candle-chart/"},{"name":"Keras","slug":"keras","permalink":"https://jukyellow.github.io/tags/keras/"},{"name":"Conv2D","slug":"conv2d","permalink":"https://jukyellow.github.io/tags/conv2d/"},{"name":"linux","slug":"linux","permalink":"https://jukyellow.github.io/tags/linux/"},{"name":"unix","slug":"unix","permalink":"https://jukyellow.github.io/tags/unix/"},{"name":"centos","slug":"centos","permalink":"https://jukyellow.github.io/tags/centos/"},{"name":"명령어","slug":"명령어","permalink":"https://jukyellow.github.io/tags/%EB%AA%85%EB%A0%B9%EC%96%B4/"},{"name":"OS버전","slug":"os버전","permalink":"https://jukyellow.github.io/tags/os%EB%B2%84%EC%A0%84/"},{"name":"hexo bug patch","slug":"hexo-bug-patch","permalink":"https://jukyellow.github.io/tags/hexo-bug-patch/"},{"name":"OCR","slug":"ocr","permalink":"https://jukyellow.github.io/tags/ocr/"},{"name":"Tesseract","slug":"tesseract","permalink":"https://jukyellow.github.io/tags/tesseract/"},{"name":"Docker","slug":"docker","permalink":"https://jukyellow.github.io/tags/docker/"},{"name":"Text추출","slug":"text추출","permalink":"https://jukyellow.github.io/tags/text%EC%B6%94%EC%B6%9C/"},{"name":"facenet","slug":"facenet","permalink":"https://jukyellow.github.io/tags/facenet/"},{"name":"google teachable machine","slug":"google-teachable-machine","permalink":"https://jukyellow.github.io/tags/google-teachable-machine/"},{"name":"face recognition","slug":"face-recognition","permalink":"https://jukyellow.github.io/tags/face-recognition/"},{"name":"marp","slug":"marp","permalink":"https://jukyellow.github.io/tags/marp/"},{"name":"markdown","slug":"markdown","permalink":"https://jukyellow.github.io/tags/markdown/"},{"name":"slide","slug":"slide","permalink":"https://jukyellow.github.io/tags/slide/"},{"name":"hexo blog","slug":"hexo-blog","permalink":"https://jukyellow.github.io/tags/hexo-blog/"},{"name":"hexo install","slug":"hexo-install","permalink":"https://jukyellow.github.io/tags/hexo-install/"}]}